{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526dd826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shiva\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- LSTM Forecasting & Validation ---\n",
      "--- (Nashik/Wheat: 2002-2023 Train, 2024 Validate) ---\n",
      "------------------------------\n",
      "Processing Training (2002-2023) Dataset\n",
      "------------------------------\n",
      "Loading Training (2002-2023) data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_2002_2023.csv...\n",
      "Loaded 6246 rows.\n",
      "Constructing 'full_date'...\n",
      "6246 rows after date construction.\n",
      "6246 rows after ensuring price columns numeric.\n",
      "Training (2002-2023) base data loaded. 6246 rows.\n",
      "------------------------------\n",
      "Processing Validation (2024) Dataset\n",
      "------------------------------\n",
      "Loading Validation (2024) data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_test_2024.csv...\n",
      "Loaded 278 rows.\n",
      "Constructing 'full_date'...\n",
      "278 rows after date construction.\n",
      "278 rows after ensuring price columns numeric.\n",
      "Validation (2024) base data loaded. 278 rows.\n",
      "\n",
      "Selected: Maharashtra/Nashik/Wheat -> Encoded: St=6291, Di=6291, Co=6291\n",
      "\n",
      "Filtering datasets using encoded values...\n",
      "\n",
      "Preparing data for LSTM (Target: avg_modal_price)...\n",
      "Creating sequences with length 120...\n",
      "Training sequences shape: X=(6126, 120, 1), y=(6126, 1)\n",
      "Validation sequences shape: X=(158, 120, 1), y=(158, 1)\n",
      "\n",
      "Building LSTM model...\n",
      "WARNING:tensorflow:From C:\\Users\\Shiva\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Shiva\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                10400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10451 (40.82 KB)\n",
      "Trainable params: 10451 (40.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting LSTM model training...\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Shiva\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "96/96 [==============================] - 17s 113ms/step - loss: 0.0249 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 5s 50ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 5s 47ms/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 14s 145ms/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 14s 148ms/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 14s 141ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 9s 95ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 4s 46ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 5s 52ms/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 14s 147ms/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 10s 109ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 5s 51ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Training finished.\n",
      "\n",
      "--- Evaluating FINAL LSTM Model Performance on 2024 Validation Data ---\n",
      "Predicting on validation data...\n",
      "5/5 [==============================] - 0s 16ms/step\n",
      "Inverse transforming scaled predictions and actuals...\n",
      "FINAL Validation R-squared (R2): 0.5457\n",
      "FINAL Validation Mean Absolute Error (MAE): 77.55\n",
      "FINAL Validation Mean Squared Error (MSE): 9952.36\n",
      "\n",
      "--- Plotting FINAL Validation Results for avg_modal_price (Actual vs. Predicted 2024) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "marker": {
          "size": 4
         },
         "mode": "lines+markers",
         "name": "Actual Modal (2024)",
         "type": "scatter",
         "x": [
          "2024-06-10T00:00:00.000000000",
          "2024-06-11T00:00:00.000000000",
          "2024-06-12T00:00:00.000000000",
          "2024-06-13T00:00:00.000000000",
          "2024-06-14T00:00:00.000000000",
          "2024-06-15T00:00:00.000000000",
          "2024-06-17T00:00:00.000000000",
          "2024-06-18T00:00:00.000000000",
          "2024-06-19T00:00:00.000000000",
          "2024-06-20T00:00:00.000000000",
          "2024-06-21T00:00:00.000000000",
          "2024-06-22T00:00:00.000000000",
          "2024-06-24T00:00:00.000000000",
          "2024-06-25T00:00:00.000000000",
          "2024-06-26T00:00:00.000000000",
          "2024-06-27T00:00:00.000000000",
          "2024-06-28T00:00:00.000000000",
          "2024-06-29T00:00:00.000000000",
          "2024-07-01T00:00:00.000000000",
          "2024-07-02T00:00:00.000000000",
          "2024-07-03T00:00:00.000000000",
          "2024-07-04T00:00:00.000000000",
          "2024-07-05T00:00:00.000000000",
          "2024-07-06T00:00:00.000000000",
          "2024-07-08T00:00:00.000000000",
          "2024-07-09T00:00:00.000000000",
          "2024-07-10T00:00:00.000000000",
          "2024-07-11T00:00:00.000000000",
          "2024-07-12T00:00:00.000000000",
          "2024-07-13T00:00:00.000000000",
          "2024-07-15T00:00:00.000000000",
          "2024-07-16T00:00:00.000000000",
          "2024-07-17T00:00:00.000000000",
          "2024-07-18T00:00:00.000000000",
          "2024-07-19T00:00:00.000000000",
          "2024-07-20T00:00:00.000000000",
          "2024-07-22T00:00:00.000000000",
          "2024-07-23T00:00:00.000000000",
          "2024-07-24T00:00:00.000000000",
          "2024-07-25T00:00:00.000000000",
          "2024-07-26T00:00:00.000000000",
          "2024-07-27T00:00:00.000000000",
          "2024-07-29T00:00:00.000000000",
          "2024-07-30T00:00:00.000000000",
          "2024-07-31T00:00:00.000000000",
          "2024-08-05T00:00:00.000000000",
          "2024-08-06T00:00:00.000000000",
          "2024-08-07T00:00:00.000000000",
          "2024-08-08T00:00:00.000000000",
          "2024-08-09T00:00:00.000000000",
          "2024-08-10T00:00:00.000000000",
          "2024-08-12T00:00:00.000000000",
          "2024-08-14T00:00:00.000000000",
          "2024-08-16T00:00:00.000000000",
          "2024-08-17T00:00:00.000000000",
          "2024-08-19T00:00:00.000000000",
          "2024-08-20T00:00:00.000000000",
          "2024-08-21T00:00:00.000000000",
          "2024-08-22T00:00:00.000000000",
          "2024-08-23T00:00:00.000000000",
          "2024-08-24T00:00:00.000000000",
          "2024-08-26T00:00:00.000000000",
          "2024-08-27T00:00:00.000000000",
          "2024-08-28T00:00:00.000000000",
          "2024-08-29T00:00:00.000000000",
          "2024-08-30T00:00:00.000000000",
          "2024-08-31T00:00:00.000000000",
          "2024-09-03T00:00:00.000000000",
          "2024-09-04T00:00:00.000000000",
          "2024-09-05T00:00:00.000000000",
          "2024-09-06T00:00:00.000000000",
          "2024-09-07T00:00:00.000000000",
          "2024-09-09T00:00:00.000000000",
          "2024-09-10T00:00:00.000000000",
          "2024-09-11T00:00:00.000000000",
          "2024-09-12T00:00:00.000000000",
          "2024-09-13T00:00:00.000000000",
          "2024-09-14T00:00:00.000000000",
          "2024-09-16T00:00:00.000000000",
          "2024-09-17T00:00:00.000000000",
          "2024-09-18T00:00:00.000000000",
          "2024-09-19T00:00:00.000000000",
          "2024-09-20T00:00:00.000000000",
          "2024-09-21T00:00:00.000000000",
          "2024-09-23T00:00:00.000000000",
          "2024-09-24T00:00:00.000000000",
          "2024-09-26T00:00:00.000000000",
          "2024-09-27T00:00:00.000000000",
          "2024-09-28T00:00:00.000000000",
          "2024-09-30T00:00:00.000000000",
          "2024-10-01T00:00:00.000000000",
          "2024-10-02T00:00:00.000000000",
          "2024-10-03T00:00:00.000000000",
          "2024-10-04T00:00:00.000000000",
          "2024-10-05T00:00:00.000000000",
          "2024-10-09T00:00:00.000000000",
          "2024-10-10T00:00:00.000000000",
          "2024-10-11T00:00:00.000000000",
          "2024-10-12T00:00:00.000000000",
          "2024-10-14T00:00:00.000000000",
          "2024-10-15T00:00:00.000000000",
          "2024-10-16T00:00:00.000000000",
          "2024-10-17T00:00:00.000000000",
          "2024-10-18T00:00:00.000000000",
          "2024-10-19T00:00:00.000000000",
          "2024-10-21T00:00:00.000000000",
          "2024-10-22T00:00:00.000000000",
          "2024-10-23T00:00:00.000000000",
          "2024-10-24T00:00:00.000000000",
          "2024-10-25T00:00:00.000000000",
          "2024-10-26T00:00:00.000000000",
          "2024-10-28T00:00:00.000000000",
          "2024-10-29T00:00:00.000000000",
          "2024-11-04T00:00:00.000000000",
          "2024-11-05T00:00:00.000000000",
          "2024-11-07T00:00:00.000000000",
          "2024-11-08T00:00:00.000000000",
          "2024-11-09T00:00:00.000000000",
          "2024-11-11T00:00:00.000000000",
          "2024-11-13T00:00:00.000000000",
          "2024-11-14T00:00:00.000000000",
          "2024-11-15T00:00:00.000000000",
          "2024-11-16T00:00:00.000000000",
          "2024-11-18T00:00:00.000000000",
          "2024-11-19T00:00:00.000000000",
          "2024-11-22T00:00:00.000000000",
          "2024-11-23T00:00:00.000000000",
          "2024-11-25T00:00:00.000000000",
          "2024-11-26T00:00:00.000000000",
          "2024-11-27T00:00:00.000000000",
          "2024-11-28T00:00:00.000000000",
          "2024-11-30T00:00:00.000000000",
          "2024-12-02T00:00:00.000000000",
          "2024-12-03T00:00:00.000000000",
          "2024-12-04T00:00:00.000000000",
          "2024-12-05T00:00:00.000000000",
          "2024-12-06T00:00:00.000000000",
          "2024-12-07T00:00:00.000000000",
          "2024-12-09T00:00:00.000000000",
          "2024-12-10T00:00:00.000000000",
          "2024-12-11T00:00:00.000000000",
          "2024-12-12T00:00:00.000000000",
          "2024-12-13T00:00:00.000000000",
          "2024-12-14T00:00:00.000000000",
          "2024-12-16T00:00:00.000000000",
          "2024-12-17T00:00:00.000000000",
          "2024-12-18T00:00:00.000000000",
          "2024-12-19T00:00:00.000000000",
          "2024-12-20T00:00:00.000000000",
          "2024-12-21T00:00:00.000000000",
          "2024-12-23T00:00:00.000000000",
          "2024-12-24T00:00:00.000000000",
          "2024-12-25T00:00:00.000000000",
          "2024-12-26T00:00:00.000000000",
          "2024-12-27T00:00:00.000000000",
          "2024-12-28T00:00:00.000000000",
          "2024-12-30T00:00:00.000000000",
          "2024-12-31T00:00:00.000000000"
         ],
         "y": {
          "bdata": "cT0K1yNBpEAAAAAAgH6jQFyPwvWobqVAZmZmZmYYpUCkcD0KV7WkQAAAAAAAP6NAAAAAAAAUpEAAAAAAAE+lQGZmZmZmTqRAXI/C9agypUAAAAAAgM6lQAAAAAAAMaNAXI/C9ajOpEAAAAAAgJSlQAAAAAAAcqRAcT0K1yPXpECkcD0KVy2lQFyPwvWoCqVAXI/C9ag4pUBcj8L1qCGkQAAAAAAAuqVApHA9CldkpEAAAAAAAO6jQAAAAAAA76VAPQrXo3B+pUAAAAAAAAKmQHE9Ctcj76VAMzMzMzNRpkAAAAAAAISlQAAAAAAAdqJAMzMzMzOPpEAAAAAAALSlQAAAAAAAzqRAAAAAAADTpEAAAAAAgKClQAAAAAAABKVApHA9CleNpEBcj8L1qPylQAAAAAAAbKVAAAAAAAB+pUAAAAAAAPakQAAAAAAA8KRApHA9ClcBpUAAAAAAAKylQAAAAAAAQqVAcT0K1yMNpUAAAAAAAC6lQAAAAAAApqVAXI/C9ajWpUAAAAAAAKakQAAAAAAAVKRAAAAAAADKpUAAAAAAAB6lQAAAAAAALqVAAAAAAABapkAAAAAAANmkQKRwPQpXJaVApHA9CleTpEDNzMzMzA6lQB+F61G4paRAXI/C9agIpUDNzMzMzO6lQDMzMzMzv6VAmpmZmZlXpUAAAAAAgCumQAAAAAAAHKZAAAAAAAD1pUDNzMzMzOykQFyPwvWoNqZAXI/C9airpUBmZmZmZiqlQAAAAAAASKRAj8L1KNyKpUCamZmZmQumQFyPwvWoEKZApHA9Clehp0AzMzMzM7umQAAAAAAAQqVAAAAAAACmpkAAAAAAAOClQAAAAAAAsKVAZmZmZmY0pkBcj8L1qBWlQAAAAAAAlKRAUrgehWsTpkAAAAAAAKWlQKRwPQpX66VAAAAAAACCpUAAAAAAAP6kQAAAAAAAdKVAAAAAAAAvpUAAAAAAAKimQAAAAACAK6ZAAAAAAABkpkCkcD0KVx2nQArXo3A95qVArkfhepTWpUDNzMzMzDKlQAAAAAAA4KVAH4XrUbirpkBcj8L1qAumQM3MzMzMIKdAmpmZmZk5pkAfhetRuBOnQAAAAAAAaqhAAAAAAACspUAAAAAAAGinQAAAAAAAXqdAXI/C9ai7p0AAAAAAACqmQKRwPQpXj6ZAUrgehWvLpkAAAAAAAJ2mQAAAAAAAbKhAAAAAAICEp0AAAAAAgAGoQB+F61G4OadAAAAAAABCp0AAAAAAAACnQK5H4XqUfKdAAAAAAABXqEAAAAAAAEamQFyPwvWoGqhAAAAAAAD9p0AAAAAAANinQK5H4XqUcKdAAAAAAADgpUAK16NwPcqnQAAAAAAAWqdAAAAAAACap0CuR+F6lFimQAAAAAAASqVAAAAAAIBopkBxPQrXI9GmQHE9Ctcj4aZAcT0K1yPNpkCkcD0KVw+mQAAAAAAAkKdAhetRuB6lp0AAAAAAgO6mQAAAAAAA8aZAXI/C9ahNp0BmZmZmZrSmQAAAAAAAd6ZAAAAAAADKpkCPwvUo3PymQArXo3A9PqdAAAAAAIA1qEAAAAAAADCnQAAAAACAz6dAAAAAAABop0AAAAAAgDioQAAAAAAACqZAZmZmZmY6p0Bcj8L1qMylQAAAAAAA8KZAMzMzMzMtpkAAAAAAgGanQA==",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Predicted Modal (2024)",
         "type": "scatter",
         "x": [
          "2024-06-10T00:00:00.000000000",
          "2024-06-11T00:00:00.000000000",
          "2024-06-12T00:00:00.000000000",
          "2024-06-13T00:00:00.000000000",
          "2024-06-14T00:00:00.000000000",
          "2024-06-15T00:00:00.000000000",
          "2024-06-17T00:00:00.000000000",
          "2024-06-18T00:00:00.000000000",
          "2024-06-19T00:00:00.000000000",
          "2024-06-20T00:00:00.000000000",
          "2024-06-21T00:00:00.000000000",
          "2024-06-22T00:00:00.000000000",
          "2024-06-24T00:00:00.000000000",
          "2024-06-25T00:00:00.000000000",
          "2024-06-26T00:00:00.000000000",
          "2024-06-27T00:00:00.000000000",
          "2024-06-28T00:00:00.000000000",
          "2024-06-29T00:00:00.000000000",
          "2024-07-01T00:00:00.000000000",
          "2024-07-02T00:00:00.000000000",
          "2024-07-03T00:00:00.000000000",
          "2024-07-04T00:00:00.000000000",
          "2024-07-05T00:00:00.000000000",
          "2024-07-06T00:00:00.000000000",
          "2024-07-08T00:00:00.000000000",
          "2024-07-09T00:00:00.000000000",
          "2024-07-10T00:00:00.000000000",
          "2024-07-11T00:00:00.000000000",
          "2024-07-12T00:00:00.000000000",
          "2024-07-13T00:00:00.000000000",
          "2024-07-15T00:00:00.000000000",
          "2024-07-16T00:00:00.000000000",
          "2024-07-17T00:00:00.000000000",
          "2024-07-18T00:00:00.000000000",
          "2024-07-19T00:00:00.000000000",
          "2024-07-20T00:00:00.000000000",
          "2024-07-22T00:00:00.000000000",
          "2024-07-23T00:00:00.000000000",
          "2024-07-24T00:00:00.000000000",
          "2024-07-25T00:00:00.000000000",
          "2024-07-26T00:00:00.000000000",
          "2024-07-27T00:00:00.000000000",
          "2024-07-29T00:00:00.000000000",
          "2024-07-30T00:00:00.000000000",
          "2024-07-31T00:00:00.000000000",
          "2024-08-05T00:00:00.000000000",
          "2024-08-06T00:00:00.000000000",
          "2024-08-07T00:00:00.000000000",
          "2024-08-08T00:00:00.000000000",
          "2024-08-09T00:00:00.000000000",
          "2024-08-10T00:00:00.000000000",
          "2024-08-12T00:00:00.000000000",
          "2024-08-14T00:00:00.000000000",
          "2024-08-16T00:00:00.000000000",
          "2024-08-17T00:00:00.000000000",
          "2024-08-19T00:00:00.000000000",
          "2024-08-20T00:00:00.000000000",
          "2024-08-21T00:00:00.000000000",
          "2024-08-22T00:00:00.000000000",
          "2024-08-23T00:00:00.000000000",
          "2024-08-24T00:00:00.000000000",
          "2024-08-26T00:00:00.000000000",
          "2024-08-27T00:00:00.000000000",
          "2024-08-28T00:00:00.000000000",
          "2024-08-29T00:00:00.000000000",
          "2024-08-30T00:00:00.000000000",
          "2024-08-31T00:00:00.000000000",
          "2024-09-03T00:00:00.000000000",
          "2024-09-04T00:00:00.000000000",
          "2024-09-05T00:00:00.000000000",
          "2024-09-06T00:00:00.000000000",
          "2024-09-07T00:00:00.000000000",
          "2024-09-09T00:00:00.000000000",
          "2024-09-10T00:00:00.000000000",
          "2024-09-11T00:00:00.000000000",
          "2024-09-12T00:00:00.000000000",
          "2024-09-13T00:00:00.000000000",
          "2024-09-14T00:00:00.000000000",
          "2024-09-16T00:00:00.000000000",
          "2024-09-17T00:00:00.000000000",
          "2024-09-18T00:00:00.000000000",
          "2024-09-19T00:00:00.000000000",
          "2024-09-20T00:00:00.000000000",
          "2024-09-21T00:00:00.000000000",
          "2024-09-23T00:00:00.000000000",
          "2024-09-24T00:00:00.000000000",
          "2024-09-26T00:00:00.000000000",
          "2024-09-27T00:00:00.000000000",
          "2024-09-28T00:00:00.000000000",
          "2024-09-30T00:00:00.000000000",
          "2024-10-01T00:00:00.000000000",
          "2024-10-02T00:00:00.000000000",
          "2024-10-03T00:00:00.000000000",
          "2024-10-04T00:00:00.000000000",
          "2024-10-05T00:00:00.000000000",
          "2024-10-09T00:00:00.000000000",
          "2024-10-10T00:00:00.000000000",
          "2024-10-11T00:00:00.000000000",
          "2024-10-12T00:00:00.000000000",
          "2024-10-14T00:00:00.000000000",
          "2024-10-15T00:00:00.000000000",
          "2024-10-16T00:00:00.000000000",
          "2024-10-17T00:00:00.000000000",
          "2024-10-18T00:00:00.000000000",
          "2024-10-19T00:00:00.000000000",
          "2024-10-21T00:00:00.000000000",
          "2024-10-22T00:00:00.000000000",
          "2024-10-23T00:00:00.000000000",
          "2024-10-24T00:00:00.000000000",
          "2024-10-25T00:00:00.000000000",
          "2024-10-26T00:00:00.000000000",
          "2024-10-28T00:00:00.000000000",
          "2024-10-29T00:00:00.000000000",
          "2024-11-04T00:00:00.000000000",
          "2024-11-05T00:00:00.000000000",
          "2024-11-07T00:00:00.000000000",
          "2024-11-08T00:00:00.000000000",
          "2024-11-09T00:00:00.000000000",
          "2024-11-11T00:00:00.000000000",
          "2024-11-13T00:00:00.000000000",
          "2024-11-14T00:00:00.000000000",
          "2024-11-15T00:00:00.000000000",
          "2024-11-16T00:00:00.000000000",
          "2024-11-18T00:00:00.000000000",
          "2024-11-19T00:00:00.000000000",
          "2024-11-22T00:00:00.000000000",
          "2024-11-23T00:00:00.000000000",
          "2024-11-25T00:00:00.000000000",
          "2024-11-26T00:00:00.000000000",
          "2024-11-27T00:00:00.000000000",
          "2024-11-28T00:00:00.000000000",
          "2024-11-30T00:00:00.000000000",
          "2024-12-02T00:00:00.000000000",
          "2024-12-03T00:00:00.000000000",
          "2024-12-04T00:00:00.000000000",
          "2024-12-05T00:00:00.000000000",
          "2024-12-06T00:00:00.000000000",
          "2024-12-07T00:00:00.000000000",
          "2024-12-09T00:00:00.000000000",
          "2024-12-10T00:00:00.000000000",
          "2024-12-11T00:00:00.000000000",
          "2024-12-12T00:00:00.000000000",
          "2024-12-13T00:00:00.000000000",
          "2024-12-14T00:00:00.000000000",
          "2024-12-16T00:00:00.000000000",
          "2024-12-17T00:00:00.000000000",
          "2024-12-18T00:00:00.000000000",
          "2024-12-19T00:00:00.000000000",
          "2024-12-20T00:00:00.000000000",
          "2024-12-21T00:00:00.000000000",
          "2024-12-23T00:00:00.000000000",
          "2024-12-24T00:00:00.000000000",
          "2024-12-25T00:00:00.000000000",
          "2024-12-26T00:00:00.000000000",
          "2024-12-27T00:00:00.000000000",
          "2024-12-28T00:00:00.000000000",
          "2024-12-30T00:00:00.000000000",
          "2024-12-31T00:00:00.000000000"
         ],
         "y": {
          "bdata": "U18kRYcqJEUNciNFYvsjRZx8JEVwyCRF3AQkRY6rI0WZLyRFhCkkRZS1JEXtwyVFaBElRWM9JUWVAiZFIRomRQFgJkV+4CZFYU4nRXjWJ0XonCdFZlYoRUg+KEVyrydFY2MoRSj0KEVZ4ilFftMqRScILEXvsyxFUOIqRbgsKkVpTSpFxPEpRWWSKUXewylFhaUpRVQyKUWTsSlF9fQpRYxGKkXEPipFhiMqRUoLKkVbZSpFzIcqRTSAKkVZhipF2t0qRRVjK0XdHitFjn0qRWzIKkUPuipF5a4qRY9zK0UWUStFVUQrRe7LKkU1lCpFthYqRdvUKUXaOypFBqQqRbPQKkUFiytFE1EsRU4BLUX/8yxFCaMtRegALkX/8i1FGB8tRV0GLUVfVi1FWL4tRWlHL0WfZzBFCHkwRRdLMUW1nDFF0qwxRbH9MUXUfjFFaWwwRdZKMEVD9i9Fl9IvRXpvL0VqqC5FDisuRfmHLUW48y1FYDwuRQq5LkVbyC9Fix4wRVdPMEVZ+C9Fcv4vRfiTMEUQ0DBFxsExRc8tMkWsHDNFXwg1RZMyNUVvRDZFHls3RQKoOEXA1ThFpwY5RUtDOUWUSjlFKX86RW86O0XuOTxFQa08RdYAPUUmCD1Fn0o9RfwgPkUghT1Ffv89Rcd8PkUG3D5FBOU+RWOmPUVakz1F8ks9RY0vPUUtLjxFRTQ6RZznOEUEAjhFtkk3RVCiNkXXiTVFx5A1RdLkNUXz2jVFAdo1RX4oNkXKGjZFYtk1RdDNNUXk7zVFD002RYZsN0Ud9DdFLt84RTGIOUV9tzpFj1s6RamVOkW/vzlFp4g5RcvJOEU=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "hovermode": "x unified",
        "legend": {
         "title": {
          "text": "Legend"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "LSTM Validation (Nashik/Wheat): Modal Price (Actual vs. Predicted 2024)"
        },
        "xaxis": {
         "title": {
          "text": "Date (2024)"
         }
        },
        "yaxis": {
         "title": {
          "text": "Price (Modal)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process finished.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow # Uncomment if needed\n",
    "\n",
    "# --- Standard Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler # <--- For LSTM scaling\n",
    "from IPython.display import display\n",
    "import traceback\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# --- Keras / TensorFlow Imports ---\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Suppress common warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# tf.random.set_seed(42) # Optional reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---  b\n",
    "# Data Paths\n",
    "DATA_PATH_TRAIN = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_2002_2023.csv\"\n",
    "DATA_PATH_VALIDATION = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_test_2024.csv\"\n",
    "\n",
    "# Target Columns & Date Construction Columns\n",
    "TARGET_COLUMNS = ['avg_min_price', 'avg_max_price', 'avg_modal_price']\n",
    "PRIMARY_TARGET = 'avg_modal_price' # Focus on one target\n",
    "DATE_COLUMN = 'full_date'; YEAR_COL = 'year'; MONTH_COL = 'month'; DAY_COL = 'date'\n",
    "VALIDATION_YEAR = 2024\n",
    "\n",
    "# Filter Selections\n",
    "SELECTED_STATE_STR = \"Maharashtra\"; SELECTED_DISTRICT_STR = \"Nashik\"; SELECTED_COMMODITY_STR = \"Wheat\"\n",
    "\n",
    "# Frequency Encoding Maps (CONFIRM THESE ARE CORRECT)\n",
    "state_name_encoding_map = {\"maharashtra\": 6291}\n",
    "district_name_encoding_map = {\"nashik\": 6291}\n",
    "commodity_name_encoding_map = {\"wheat\": 6291}\n",
    "\n",
    "# --- LSTM Configuration ---\n",
    "SEQUENCE_LENGTH = 60     # Number of past days to use for predicting the next day - NEEDS TUNING\n",
    "LSTM_UNITS = 50        # Number of units in LSTM layer - NEEDS TUNING\n",
    "DROPOUT_RATE = 0.2       # Dropout for regularization\n",
    "EPOCHS = 50             # Max epochs (use EarlyStopping) - NEEDS TUNING\n",
    "BATCH_SIZE = 32      # Batch size for training - NEEDS TUNING\n",
    "\n",
    "# --- Helper Functions (Outlier removal, Loading - Minor changes needed) ---\n",
    "def remove_outliers_iqr(df, columns_to_check):\n",
    "    df_filtered = df.copy(); initial_rows = len(df_filtered)\n",
    "    valid_columns = [col for col in columns_to_check if col in df_filtered.columns and pd.api.types.is_numeric_dtype(df_filtered[col])]\n",
    "    if not valid_columns: return df_filtered\n",
    "    subset_for_iqr = df_filtered[valid_columns]\n",
    "    Q1 = subset_for_iqr.quantile(0.25); Q3 = subset_for_iqr.quantile(0.75); IQR = Q3 - Q1\n",
    "    mask = ~((subset_for_iqr < (Q1 - 1.5 * IQR)) | (subset_for_iqr > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    df_filtered = df_filtered[mask]; rows_removed = initial_rows - len(df_filtered)\n",
    "    if rows_removed > 0: print(f\"Removed {rows_removed} rows via IQR.\")\n",
    "    return df_filtered\n",
    "\n",
    "# --- Data Loading and Preprocessing Function (Simplified for LSTM base) ---\n",
    "def load_and_preprocess_base_data(path, date_col_name, year_col, month_col, day_col, all_potential_targets, dataset_name=\"Training\"):\n",
    "    \"\"\"Loads data, constructs date, basic cleaning. Returns essential cols.\"\"\"\n",
    "    print(\"-\" * 30); print(f\"Processing {dataset_name} Dataset\"); print(\"-\" * 30)\n",
    "    try:\n",
    "        print(f\"Loading {dataset_name} data from {path}...\"); df = pd.read_csv(path); print(f\"Loaded {len(df)} rows.\")\n",
    "        # 1. Construct Date\n",
    "        date_components_cols = [year_col, month_col, day_col]\n",
    "        if not all(col in df.columns for col in date_components_cols): print(f\"Error: Date component cols missing: {[c for c in date_components_cols if c not in df.columns]}\"); return None\n",
    "        for col in date_components_cols: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=date_components_cols, inplace=True)\n",
    "        print(f\"Constructing '{date_col_name}'...\");\n",
    "        df[date_col_name] = pd.to_datetime({'year': df[year_col], 'month': df[month_col], 'day': df[day_col]}, errors='coerce')\n",
    "        initial_rows_date = len(df); df.dropna(subset=[date_col_name], inplace=True)\n",
    "        if initial_rows_date > len(df): print(f\"Dropped {initial_rows_date - len(df)} rows due to invalid date components.\")\n",
    "        print(f\"{len(df)} rows after date construction.\")\n",
    "\n",
    "        # 2. Keep ONLY necessary columns for filtering + target + date\n",
    "        required_numeric_filter_cols = ['state_name', 'district_name', 'commodity_name']\n",
    "        keep_cols = [date_col_name] + all_potential_targets + required_numeric_filter_cols\n",
    "        missing_req_cols = [col for col in keep_cols if col not in df.columns]\n",
    "        if missing_req_cols: print(f\"Error: Required columns missing: {missing_req_cols}\"); print(f\"Available: {df.columns.tolist()}\"); return None\n",
    "        df = df[keep_cols] # Keep only needed columns early on\n",
    "\n",
    "        # 3. Ensure Price/Target columns are numeric\n",
    "        for col in all_potential_targets: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=all_potential_targets, how='any', inplace=True)\n",
    "        print(f\"{len(df)} rows after ensuring price columns numeric.\")\n",
    "\n",
    "        # 4. Ensure Filter columns are numeric (encoded)\n",
    "        for col in required_numeric_filter_cols:\n",
    "             if not pd.api.types.is_numeric_dtype(df[col]): print(f\"Error: Col '{col}' expected numeric but isn't.\"); return None\n",
    "\n",
    "        # 5. Apply IQR Outlier Removal (Optional, on targets)\n",
    "        # df = remove_outliers_iqr(df, all_potential_targets)\n",
    "\n",
    "        df.sort_values(date_col_name, inplace=True)\n",
    "        print(f\"{dataset_name} base data loaded. {len(df)} rows.\")\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError: print(f\"Error: {dataset_name} file not found at {path}\"); return None\n",
    "    except Exception as e: print(f\"Error loading/preprocessing {dataset_name}: {e}\"); traceback.print_exc(); return None\n",
    "\n",
    "\n",
    "# --- Sequence Creation Function ---\n",
    "def create_sequences(data, sequence_length):\n",
    "    \"\"\"Creates sequences of data for LSTM.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:(i + sequence_length)]) # Sequence of inputs\n",
    "        y.append(data[i + sequence_length])    # Value to predict\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- Evaluation Metrics Function (No changes) ---\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # ... (same as before) ...\n",
    "    y_true = np.array(y_true).flatten(); y_pred = np.array(y_pred).flatten()\n",
    "    valid_mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    y_true = y_true[valid_mask]; y_pred = y_pred[valid_mask]\n",
    "    if len(y_true) == 0: print(\"Warning: No valid points for metric calculation.\"); return np.nan, np.nan, np.nan\n",
    "    try:\n",
    "        r2 = r2_score(y_true, y_pred); mae = mean_absolute_error(y_true, y_pred); mse = mean_squared_error(y_true, y_pred)\n",
    "        return r2, mae, mse\n",
    "    except Exception as e: print(f\"Error calculating metrics: {e}\"); return np.nan, np.nan, np.nan\n",
    "\n",
    "\n",
    "# --- Plotting Function for Validation (Adapted for LSTM Output) ---\n",
    "def plot_lstm_validation_results(dates_val, actuals_inv, preds_inv, target_column, title):\n",
    "    \"\"\"Plots actuals vs predictions for validation period.\"\"\"\n",
    "    import plotly.graph_objects as go # Import locally if not globally\n",
    "    fig = go.Figure(); target_label = target_column.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()\n",
    "\n",
    "    # Actuals\n",
    "    fig.add_trace(go.Scatter(x=dates_val, y=actuals_inv.flatten(), mode='lines+markers', name=f'Actual {target_label} ({VALIDATION_YEAR})', line=dict(color='blue'), marker=dict(size=4)))\n",
    "\n",
    "    # Predictions\n",
    "    fig.add_trace(go.Scatter(x=dates_val, y=preds_inv.flatten(), mode='lines', name=f'Predicted {target_label} ({VALIDATION_YEAR})', line=dict(color='red')))\n",
    "\n",
    "    fig.update_layout(title=title, xaxis_title=f'Date ({VALIDATION_YEAR})', yaxis_title=f'Price ({target_label})', hovermode=\"x unified\", legend_title_text='Legend')\n",
    "    return fig\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "print(\"--- LSTM Forecasting & Validation ---\") # Changed Title\n",
    "print(f\"--- (Nashik/Wheat: 2002-2023 Train, {VALIDATION_YEAR} Validate) ---\")\n",
    "\n",
    "# 1. Load Base Data\n",
    "df_train_base = load_and_preprocess_base_data(DATA_PATH_TRAIN, DATE_COLUMN, YEAR_COL, MONTH_COL, DAY_COL, TARGET_COLUMNS, \"Training (2002-2023)\")\n",
    "df_val_base = load_and_preprocess_base_data(DATA_PATH_VALIDATION, DATE_COLUMN, YEAR_COL, MONTH_COL, DAY_COL, TARGET_COLUMNS, f\"Validation ({VALIDATION_YEAR})\")\n",
    "\n",
    "# Init flags/variables\n",
    "model = None\n",
    "\n",
    "if df_train_base is not None and df_val_base is not None:\n",
    "    # 2. Get Encoded Values for Filtering\n",
    "    try:\n",
    "        selected_state_key=SELECTED_STATE_STR.strip().lower(); selected_district_key=SELECTED_DISTRICT_STR.strip().lower(); selected_commodity_key=SELECTED_COMMODITY_STR.strip().lower()\n",
    "        encoded_state = state_name_encoding_map.get(selected_state_key); encoded_district = district_name_encoding_map.get(selected_district_key); encoded_commodity = commodity_name_encoding_map.get(selected_commodity_key)\n",
    "        lookup_failed = False\n",
    "        if encoded_state is None: print(f\"Error: State '{SELECTED_STATE_STR}' missing map.\"); lookup_failed=True\n",
    "        if encoded_district is None: print(f\"Error: District '{SELECTED_DISTRICT_STR}' missing map.\"); lookup_failed=True\n",
    "        if encoded_commodity is None: print(f\"Error: Commodity '{SELECTED_COMMODITY_STR}' missing map.\"); lookup_failed=True\n",
    "        if lookup_failed: print(\"Check maps.\"); df_train_base=df_val_base=None\n",
    "        else: print(f\"\\nSelected: {SELECTED_STATE_STR}/{SELECTED_DISTRICT_STR}/{SELECTED_COMMODITY_STR} -> Encoded: St={encoded_state}, Di={encoded_district}, Co={encoded_commodity}\")\n",
    "    except Exception as e: print(f\"Error mapping lookup: {e}\"); df_train_base = df_val_base = None\n",
    "\n",
    "if df_train_base is not None and df_val_base is not None:\n",
    "    # 3. Filtering Data\n",
    "    print(f\"\\nFiltering datasets using encoded values...\")\n",
    "    filter_cols_num = ['state_name', 'district_name', 'commodity_name']\n",
    "    if not all(col in df_train_base.columns for col in filter_cols_num): print(\"Error: Encoded filter cols missing Training.\"); filtered_df_train = pd.DataFrame()\n",
    "    else: filtered_df_train = df_train_base[(df_train_base['state_name'] == encoded_state) & (df_train_base['district_name'] == encoded_district) & (df_train_base['commodity_name'] == encoded_commodity)].copy(); filtered_df_train.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "    if not all(col in df_val_base.columns for col in filter_cols_num): print(\"Error: Encoded filter cols missing Validation.\"); filtered_df_val = pd.DataFrame()\n",
    "    else: filtered_df_val = df_val_base[(df_val_base['state_name'] == encoded_state) & (df_val_base['district_name'] == encoded_district) & (df_val_base['commodity_name'] == encoded_commodity)].copy(); filtered_df_val.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "\n",
    "    if filtered_df_train.empty: print(\"\\nWarning: No training data after filtering.\")\n",
    "    if filtered_df_val.empty: print(\"\\nWarning: No validation data after filtering.\")\n",
    "\n",
    "    # 4. Prepare Data for LSTM (Focusing on PRIMARY_TARGET)\n",
    "    if not filtered_df_train.empty and not filtered_df_val.empty:\n",
    "        print(f\"\\nPreparing data for LSTM (Target: {PRIMARY_TARGET})...\")\n",
    "\n",
    "        # Select target series and ensure correct shape (n_samples, 1)\n",
    "        train_series = filtered_df_train[PRIMARY_TARGET].values.reshape(-1, 1)\n",
    "        val_series = filtered_df_val[PRIMARY_TARGET].values.reshape(-1, 1)\n",
    "        val_dates = filtered_df_val[DATE_COLUMN].values # Keep dates for plotting\n",
    "\n",
    "        # Scale data (Fit only on training data)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_train_data = scaler.fit_transform(train_series)\n",
    "        scaled_val_data = scaler.transform(val_series) # Use same scaler\n",
    "\n",
    "        # Create sequences\n",
    "        print(f\"Creating sequences with length {SEQUENCE_LENGTH}...\")\n",
    "        X_train, y_train = create_sequences(scaled_train_data, SEQUENCE_LENGTH)\n",
    "        X_val, y_val = create_sequences(scaled_val_data, SEQUENCE_LENGTH)\n",
    "\n",
    "        # Validation dates need adjustment: remove first `SEQUENCE_LENGTH` dates\n",
    "        # as they don't have a corresponding prediction in this simple setup.\n",
    "        dates_val_for_plotting = val_dates[SEQUENCE_LENGTH:]\n",
    "        # Actual validation values corresponding to predictions\n",
    "        y_val_actual_unscaled = val_series[SEQUENCE_LENGTH:] # Unscaled actuals\n",
    "\n",
    "        if X_train.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "             print(\"Error: Not enough data to create sequences for training or validation after filtering.\")\n",
    "             model = None # Prevent proceeding\n",
    "        else:\n",
    "             print(f\"Training sequences shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "             print(f\"Validation sequences shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "\n",
    "             # --- 5. Build LSTM Model ---\n",
    "             print(\"\\nBuilding LSTM model...\")\n",
    "             model = Sequential()\n",
    "             model.add(LSTM(LSTM_UNITS, activation='relu', # Or 'tanh'\n",
    "                            input_shape=(SEQUENCE_LENGTH, 1))) # Input: sequence_length time steps, 1 feature\n",
    "             model.add(Dropout(DROPOUT_RATE))\n",
    "             # Add more LSTM layers if needed:\n",
    "             # model.add(LSTM(LSTM_UNITS // 2, activation='relu', return_sequences=True))\n",
    "             # model.add(Dropout(DROPOUT_RATE))\n",
    "             model.add(Dense(1)) # Output layer: predicts 1 value\n",
    "\n",
    "             model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "             model.summary()\n",
    "\n",
    "             # --- 6. Train LSTM Model ---\n",
    "             print(\"\\nStarting LSTM model training...\")\n",
    "             early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "             history = model.fit(\n",
    "                 X_train, y_train,\n",
    "                 epochs=EPOCHS,\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stopping],\n",
    "                 verbose=1 # Set to 1 or 2 for progress, 0 for silent\n",
    "             )\n",
    "             print(\"Training finished.\")\n",
    "\n",
    "    # --- 7. Evaluate on Validation Set ---\n",
    "    if model is not None and 'X_val' in locals() and X_val.shape[0] > 0:\n",
    "        print(f\"\\n--- Evaluating FINAL LSTM Model Performance on {VALIDATION_YEAR} Validation Data ---\")\n",
    "        print(\"Predicting on validation data...\")\n",
    "        predictions_scaled = model.predict(X_val)\n",
    "\n",
    "        # Inverse transform predictions and actuals\n",
    "        print(\"Inverse transforming scaled predictions and actuals...\")\n",
    "        try:\n",
    "             predictions_inv = scaler.inverse_transform(predictions_scaled)\n",
    "             # y_val_actual_unscaled was stored earlier\n",
    "             actuals_inv = y_val_actual_unscaled\n",
    "\n",
    "             # Ensure shapes match for metric calculation\n",
    "             min_len_eval = min(len(actuals_inv), len(predictions_inv))\n",
    "             if len(actuals_inv) != len(predictions_inv):\n",
    "                 print(f\"Warning: Length mismatch after prediction/scaling. Actuals: {len(actuals_inv)}, Preds: {len(predictions_inv)}. Truncating.\")\n",
    "             actuals_inv = actuals_inv[:min_len_eval]\n",
    "             predictions_inv = predictions_inv[:min_len_eval]\n",
    "             dates_val_for_plotting = dates_val_for_plotting[:min_len_eval] # Adjust dates too\n",
    "\n",
    "             # Calculate metrics\n",
    "             if len(actuals_inv) > 0:\n",
    "                 r2_val, mae_val, mse_val = calculate_metrics(actuals_inv, predictions_inv)\n",
    "                 print(f\"FINAL Validation R-squared (R2): {r2_val:.4f}\")\n",
    "                 print(f\"FINAL Validation Mean Absolute Error (MAE): {mae_val:.2f}\")\n",
    "                 print(f\"FINAL Validation Mean Squared Error (MSE): {mse_val:.2f}\")\n",
    "\n",
    "                 # --- 8. Plot Validation Results ---\n",
    "                 print(f\"\\n--- Plotting FINAL Validation Results for {PRIMARY_TARGET} (Actual vs. Predicted {VALIDATION_YEAR}) ---\")\n",
    "                 plot_title_val = f'LSTM Validation (Nashik/Wheat): {PRIMARY_TARGET.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()} Price (Actual vs. Predicted {VALIDATION_YEAR})'\n",
    "                 fig_val = plot_lstm_validation_results(dates_val_for_plotting, actuals_inv, predictions_inv, PRIMARY_TARGET, plot_title_val)\n",
    "                 fig_val.show()\n",
    "             else:\n",
    "                 print(\"Skipping metrics and plotting: No valid data points after alignment/scaling.\")\n",
    "\n",
    "        except Exception as e:\n",
    "             print(f\"Error during prediction, scaling or evaluation: {e}\")\n",
    "             traceback.print_exc()\n",
    "\n",
    "    elif model is None:\n",
    "         print(\"\\nSkipping evaluation and plotting because model training failed or insufficient data.\")\n",
    "    else: # Handle cases where filtering worked but sequence creation failed\n",
    "         print(\"\\nCannot proceed: lack of data after filtering or sequence creation.\")\n",
    "else:\n",
    "    print(\"\\nFailed during data loading, preprocessing, or mapping lookup.\")\n",
    "\n",
    "print(\"\\nProcess finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07af1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acff607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "964e90a3",
   "metadata": {},
   "source": [
    "## lstm with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa48c2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM Forecasting & Validation with KerasTuner ---\n",
      "--- (Nashik/Wheat: 2002-2023 Train, 2024 Validate) ---\n",
      "------------------------------\n",
      "Processing Training (2002-2023) Dataset\n",
      "------------------------------\n",
      "Loading Training (2002-2023) data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_2002_2023.csv...\n",
      "Loaded 6246 rows.\n",
      "Constructing 'full_date'...\n",
      "6246 rows after date construction.\n",
      "6246 rows after ensuring price columns numeric.\n",
      "Training (2002-2023) base data loaded. 6246 rows.\n",
      "------------------------------\n",
      "Processing Validation (2024) Dataset\n",
      "------------------------------\n",
      "Loading Validation (2024) data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_test_2024.csv...\n",
      "Loaded 278 rows.\n",
      "Constructing 'full_date'...\n",
      "278 rows after date construction.\n",
      "278 rows after ensuring price columns numeric.\n",
      "Validation (2024) base data loaded. 278 rows.\n",
      "\n",
      "Selected: Maharashtra/Nashik/Wheat -> Encoded: St=6291, Di=6291, Co=6291\n",
      "\n",
      "Filtering datasets using encoded values...\n",
      "\n",
      "Preparing data for LSTM (Target: avg_modal_price)...\n",
      "Creating sequences with length 60...\n",
      "Training sequences shape: X=(6186, 60, 1), y=(6186, 1)\n",
      "Validation sequences shape: X=(218, 60, 1), y=(218, 1)\n",
      "\n",
      "Starting KerasTuner hyperparameter search...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 243\u001b[0m\n\u001b[0;32m    240\u001b[0m search_early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Stop trials early\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Run the search\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEARCH_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Max epochs per trial\u001b[39;49;00m\n\u001b[0;32m    245\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msearch_early_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m             \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Set to 1 to see trial progress\u001b[39;49;00m\n\u001b[0;32m    249\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHyperparameter search finished.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    252\u001b[0m tuner\u001b[38;5;241m.\u001b[39mresults_summary(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Show the best trial summary\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow keras-tuner # Uncomment if needed\n",
    "\n",
    "# --- Standard Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display\n",
    "import traceback\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# --- Keras / TensorFlow Imports ---\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam # For tuning learning rate\n",
    "# Or alternatively, sometimes just:\n",
    "# from tensorflow.keras import optimizers # And then use optimizers.Adam later\n",
    "import keras_tuner as kt # <--- Import KerasTuner\n",
    "\n",
    "# Suppress common warnings & TF logs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TensorFlow INFO messages\n",
    "# tf.random.set_seed(42) # Optional reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Data Paths\n",
    "DATA_PATH_TRAIN = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_2002_2023.csv\"\n",
    "DATA_PATH_VALIDATION = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_test_2024.csv\"\n",
    "\n",
    "# Target Columns & Date Construction Columns\n",
    "TARGET_COLUMNS = ['avg_min_price', 'avg_max_price', 'avg_modal_price']\n",
    "PRIMARY_TARGET = 'avg_modal_price' # Focus on one target\n",
    "DATE_COLUMN = 'full_date'; YEAR_COL = 'year'; MONTH_COL = 'month'; DAY_COL = 'date'\n",
    "VALIDATION_YEAR = 2024\n",
    "\n",
    "# Filter Selections\n",
    "SELECTED_STATE_STR = \"Maharashtra\"; SELECTED_DISTRICT_STR = \"Nashik\"; SELECTED_COMMODITY_STR = \"Wheat\"\n",
    "\n",
    "# Frequency Encoding Maps (CONFIRM THESE ARE CORRECT)\n",
    "state_name_encoding_map = {\"maharashtra\": 6291}\n",
    "district_name_encoding_map = {\"nashik\": 6291}\n",
    "commodity_name_encoding_map = {\"wheat\": 6291}\n",
    "\n",
    "# --- LSTM & Tuner Configuration ---\n",
    "SEQUENCE_LENGTH = 60     # Number of past days - Keep fixed during tuning for simplicity\n",
    "# Hyperparameters below will be tuned by KerasTuner\n",
    "# Define ranges later in the build_model function\n",
    "# LSTM_UNITS = 50\n",
    "# DROPOUT_RATE = 0.2\n",
    "# LEARNING_RATE = 0.001 # Example default, will be tuned\n",
    "KERAS_TUNER_MAX_TRIALS = 20 # How many different hyperparameter sets to try\n",
    "KERAS_TUNER_EXECUTIONS = 2  # How many times to train each set (for stability)\n",
    "KERAS_TUNER_PROJECT_NAME = 'lstm_wheat_price_tuning' # Folder to save results\n",
    "SEARCH_EPOCHS = 20          # Max epochs *per trial* during search (EarlyStopping recommended)\n",
    "FINAL_EPOCHS = 100         # Max epochs for training the *final* best model\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- Helper Functions (remove_outliers_iqr, Loading, Metrics, Plotting - NO CHANGES needed) ---\n",
    "def remove_outliers_iqr(df, columns_to_check):\n",
    "    df_filtered = df.copy(); initial_rows = len(df_filtered)\n",
    "    valid_columns = [col for col in columns_to_check if col in df_filtered.columns and pd.api.types.is_numeric_dtype(df_filtered[col])]\n",
    "    if not valid_columns: return df_filtered\n",
    "    subset_for_iqr = df_filtered[valid_columns]\n",
    "    Q1 = subset_for_iqr.quantile(0.25); Q3 = subset_for_iqr.quantile(0.75); IQR = Q3 - Q1\n",
    "    mask = ~((subset_for_iqr < (Q1 - 1.5 * IQR)) | (subset_for_iqr > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    df_filtered = df_filtered[mask]; rows_removed = initial_rows - len(df_filtered)\n",
    "    if rows_removed > 0: print(f\"Removed {rows_removed} rows via IQR.\")\n",
    "    return df_filtered\n",
    "\n",
    "def load_and_preprocess_base_data(path, date_col_name, year_col, month_col, day_col, all_potential_targets, dataset_name=\"Training\"):\n",
    "    print(\"-\" * 30); print(f\"Processing {dataset_name} Dataset\"); print(\"-\" * 30)\n",
    "    try:\n",
    "        print(f\"Loading {dataset_name} data from {path}...\"); df = pd.read_csv(path); print(f\"Loaded {len(df)} rows.\")\n",
    "        # 1. Construct Date\n",
    "        date_components_cols = [year_col, month_col, day_col]\n",
    "        if not all(col in df.columns for col in date_components_cols): print(f\"Error: Date component cols missing: {[c for c in date_components_cols if c not in df.columns]}\"); return None\n",
    "        for col in date_components_cols: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=date_components_cols, inplace=True)\n",
    "        print(f\"Constructing '{date_col_name}'...\");\n",
    "        df[date_col_name] = pd.to_datetime({'year': df[year_col], 'month': df[month_col], 'day': df[day_col]}, errors='coerce')\n",
    "        initial_rows_date = len(df); df.dropna(subset=[date_col_name], inplace=True)\n",
    "        if initial_rows_date > len(df): print(f\"Dropped {initial_rows_date - len(df)} rows due to invalid date components.\")\n",
    "        print(f\"{len(df)} rows after date construction.\")\n",
    "        # 2. Keep ONLY necessary columns\n",
    "        required_numeric_filter_cols = ['state_name', 'district_name', 'commodity_name']\n",
    "        keep_cols = [date_col_name] + all_potential_targets + required_numeric_filter_cols\n",
    "        missing_req_cols = [col for col in keep_cols if col not in df.columns]\n",
    "        if missing_req_cols: print(f\"Error: Required columns missing: {missing_req_cols}\"); print(f\"Available: {df.columns.tolist()}\"); return None\n",
    "        df = df[keep_cols]\n",
    "        # 3. Ensure Price/Target columns are numeric\n",
    "        for col in all_potential_targets: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=all_potential_targets, how='any', inplace=True)\n",
    "        print(f\"{len(df)} rows after ensuring price columns numeric.\")\n",
    "        # 4. Ensure Filter columns are numeric\n",
    "        for col in required_numeric_filter_cols:\n",
    "             if not pd.api.types.is_numeric_dtype(df[col]): print(f\"Error: Col '{col}' expected numeric but isn't.\"); return None\n",
    "        # 5. Apply IQR Outlier Removal (Optional)\n",
    "        # df = remove_outliers_iqr(df, all_potential_targets)\n",
    "        df.sort_values(date_col_name, inplace=True)\n",
    "        print(f\"{dataset_name} base data loaded. {len(df)} rows.\")\n",
    "        return df\n",
    "    except FileNotFoundError: print(f\"Error: {dataset_name} file not found at {path}\"); return None\n",
    "    except Exception as e: print(f\"Error loading/preprocessing {dataset_name}: {e}\"); traceback.print_exc(); return None\n",
    "\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    if len(data) <= sequence_length: return np.array(X), np.array(y) # Handle case with insufficient data\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:(i + sequence_length)])\n",
    "        y.append(data[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = np.array(y_true).flatten(); y_pred = np.array(y_pred).flatten()\n",
    "    valid_mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    y_true = y_true[valid_mask]; y_pred = y_pred[valid_mask]\n",
    "    if len(y_true) == 0: print(\"Warning: No valid points for metric calculation.\"); return np.nan, np.nan, np.nan\n",
    "    try:\n",
    "        r2 = r2_score(y_true, y_pred); mae = mean_absolute_error(y_true, y_pred); mse = mean_squared_error(y_true, y_pred)\n",
    "        return r2, mae, mse\n",
    "    except Exception as e: print(f\"Error calculating metrics: {e}\"); return np.nan, np.nan, np.nan\n",
    "\n",
    "def plot_lstm_validation_results(dates_val, actuals_inv, preds_inv, target_column, title):\n",
    "    import plotly.graph_objects as go\n",
    "    fig = go.Figure(); target_label = target_column.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()\n",
    "    fig.add_trace(go.Scatter(x=dates_val, y=actuals_inv.flatten(), mode='lines+markers', name=f'Actual {target_label} ({VALIDATION_YEAR})', line=dict(color='blue'), marker=dict(size=4)))\n",
    "    fig.add_trace(go.Scatter(x=dates_val, y=preds_inv.flatten(), mode='lines', name=f'Predicted {target_label} ({VALIDATION_YEAR})', line=dict(color='red')))\n",
    "    fig.update_layout(title=title, xaxis_title=f'Date ({VALIDATION_YEAR})', yaxis_title=f'Price ({target_label})', hovermode=\"x unified\", legend_title_text='Legend')\n",
    "    return fig\n",
    "\n",
    "\n",
    "# --- NEW: KerasTuner Model Building Function ---\n",
    "def build_lstm_model(hp):\n",
    "    \"\"\"Builds a compiled LSTM model with hyperparameters defined by KerasTuner.\"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tune the number of units in the first LSTM layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    # Tune learning rate for Adam optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(LSTM(units=hp_units, activation='relu', # Consider 'tanh' as well: hp.Choice('activation', ['relu', 'tanh'])\n",
    "                   input_shape=(SEQUENCE_LENGTH, 1))) # Input shape: (timesteps, features)\n",
    "    model.add(Dropout(rate=hp_dropout))\n",
    "    # Potentially add more layers here, tuning their units/dropout as well\n",
    "    # model.add(LSTM(units=hp.Int('units_l2', ...), return_sequences=True))\n",
    "    # model.add(Dropout(rate=hp.Float('dropout_l2', ...)))\n",
    "    model.add(Dense(1)) # Output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "print(\"--- LSTM Forecasting & Validation with KerasTuner ---\")\n",
    "print(f\"--- (Nashik/Wheat: 2002-2023 Train, {VALIDATION_YEAR} Validate) ---\")\n",
    "\n",
    "# 1. Load Base Data\n",
    "df_train_base = load_and_preprocess_base_data(DATA_PATH_TRAIN, DATE_COLUMN, YEAR_COL, MONTH_COL, DAY_COL, TARGET_COLUMNS, \"Training (2002-2023)\")\n",
    "df_val_base = load_and_preprocess_base_data(DATA_PATH_VALIDATION, DATE_COLUMN, YEAR_COL, MONTH_COL, DAY_COL, TARGET_COLUMNS, f\"Validation ({VALIDATION_YEAR})\")\n",
    "\n",
    "# Init model variable\n",
    "final_model = None\n",
    "scaler = None # Make scaler accessible later\n",
    "\n",
    "if df_train_base is not None and df_val_base is not None:\n",
    "    # 2. Get Encoded Values for Filtering\n",
    "    try:\n",
    "        selected_state_key=SELECTED_STATE_STR.strip().lower(); selected_district_key=SELECTED_DISTRICT_STR.strip().lower(); selected_commodity_key=SELECTED_COMMODITY_STR.strip().lower()\n",
    "        encoded_state = state_name_encoding_map.get(selected_state_key); encoded_district = district_name_encoding_map.get(selected_district_key); encoded_commodity = commodity_name_encoding_map.get(selected_commodity_key)\n",
    "        lookup_failed = False\n",
    "        if encoded_state is None: print(f\"Error: State '{SELECTED_STATE_STR}' missing map.\"); lookup_failed=True\n",
    "        if encoded_district is None: print(f\"Error: District '{SELECTED_DISTRICT_STR}' missing map.\"); lookup_failed=True\n",
    "        if encoded_commodity is None: print(f\"Error: Commodity '{SELECTED_COMMODITY_STR}' missing map.\"); lookup_failed=True\n",
    "        if lookup_failed: print(\"Check maps.\"); df_train_base=df_val_base=None\n",
    "        else: print(f\"\\nSelected: {SELECTED_STATE_STR}/{SELECTED_DISTRICT_STR}/{SELECTED_COMMODITY_STR} -> Encoded: St={encoded_state}, Di={encoded_district}, Co={encoded_commodity}\")\n",
    "    except Exception as e: print(f\"Error mapping lookup: {e}\"); df_train_base = df_val_base = None\n",
    "\n",
    "if df_train_base is not None and df_val_base is not None:\n",
    "    # 3. Filtering Data\n",
    "    print(f\"\\nFiltering datasets using encoded values...\")\n",
    "    filter_cols_num = ['state_name', 'district_name', 'commodity_name']\n",
    "    if not all(col in df_train_base.columns for col in filter_cols_num): print(\"Error: Encoded filter cols missing Training.\"); filtered_df_train = pd.DataFrame()\n",
    "    else: filtered_df_train = df_train_base[(df_train_base['state_name'] == encoded_state) & (df_train_base['district_name'] == encoded_district) & (df_train_base['commodity_name'] == encoded_commodity)].copy(); filtered_df_train.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "    if not all(col in df_val_base.columns for col in filter_cols_num): print(\"Error: Encoded filter cols missing Validation.\"); filtered_df_val = pd.DataFrame()\n",
    "    else: filtered_df_val = df_val_base[(df_val_base['state_name'] == encoded_state) & (df_val_base['district_name'] == encoded_district) & (df_val_base['commodity_name'] == encoded_commodity)].copy(); filtered_df_val.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "\n",
    "    if filtered_df_train.empty: print(\"\\nWarning: No training data after filtering.\")\n",
    "    if filtered_df_val.empty: print(\"\\nWarning: No validation data after filtering.\")\n",
    "\n",
    "    # 4. Prepare Data for LSTM (Target: PRIMARY_TARGET)\n",
    "    if not filtered_df_train.empty and not filtered_df_val.empty:\n",
    "        print(f\"\\nPreparing data for LSTM (Target: {PRIMARY_TARGET})...\")\n",
    "        train_series = filtered_df_train[PRIMARY_TARGET].values.reshape(-1, 1)\n",
    "        val_series = filtered_df_val[PRIMARY_TARGET].values.reshape(-1, 1)\n",
    "        val_dates = filtered_df_val[DATE_COLUMN].values # Keep dates\n",
    "\n",
    "        # Scale data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1)) # Assign to global scope\n",
    "        scaled_train_data = scaler.fit_transform(train_series)\n",
    "        scaled_val_data = scaler.transform(val_series)\n",
    "\n",
    "        # Create sequences\n",
    "        print(f\"Creating sequences with length {SEQUENCE_LENGTH}...\")\n",
    "        X_train, y_train = create_sequences(scaled_train_data, SEQUENCE_LENGTH)\n",
    "        X_val, y_val = create_sequences(scaled_val_data, SEQUENCE_LENGTH)\n",
    "        dates_val_for_plotting = val_dates[SEQUENCE_LENGTH:] # Adjusted dates\n",
    "        y_val_actual_unscaled = val_series[SEQUENCE_LENGTH:] # Adjusted unscaled actuals\n",
    "\n",
    "        if X_train.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "             print(\"Error: Not enough data to create sequences. Try shorter SEQUENCE_LENGTH or check filters.\")\n",
    "        else:\n",
    "             print(f\"Training sequences shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "             print(f\"Validation sequences shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "\n",
    "             # --- 5. Hyperparameter Tuning with KerasTuner ---\n",
    "             print(\"\\nStarting KerasTuner hyperparameter search...\")\n",
    "             tuner = kt.BayesianOptimization(\n",
    "                 hypermodel=build_lstm_model,\n",
    "                 objective='val_loss', # Minimize validation loss\n",
    "                 max_trials=KERAS_TUNER_MAX_TRIALS, # How many hyperparameter combinations to test\n",
    "                 executions_per_trial=KERAS_TUNER_EXECUTIONS, # Train each combination multiple times for stability\n",
    "                 directory='keras_tuner_dir', # Directory to store results\n",
    "                 project_name=KERAS_TUNER_PROJECT_NAME,\n",
    "                 overwrite=True # Overwrite previous logs for this project\n",
    "             )\n",
    "\n",
    "             # Define EarlyStopping for the search phase\n",
    "             search_early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0) # Stop trials early\n",
    "\n",
    "             # Run the search\n",
    "             tuner.search(X_train, y_train,\n",
    "                          epochs=SEARCH_EPOCHS, # Max epochs per trial\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          validation_data=(X_val, y_val),\n",
    "                          callbacks=[search_early_stopping],\n",
    "                          verbose=0 # Set to 1 to see trial progress\n",
    "                         )\n",
    "\n",
    "             print(\"\\nHyperparameter search finished.\")\n",
    "             tuner.results_summary(num_trials=1) # Show the best trial summary\n",
    "\n",
    "             # Get the optimal hyperparameters\n",
    "             best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "             print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal hyperparameters found are:\n",
    "- Units: {best_hps.get('units')}\n",
    "- Dropout: {best_hps.get('dropout'):.2f}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "             \"\"\")\n",
    "\n",
    "             # --- 6. Build and Train FINAL Model with Best Hyperparameters ---\n",
    "             print(\"\\nBuilding and training final model with best hyperparameters...\")\n",
    "             # Build the model with the best hp\n",
    "             final_model = tuner.hypermodel.build(best_hps) # Recommended way\n",
    "\n",
    "             # Define EarlyStopping for the final training phase\n",
    "             final_early_stopping = EarlyStopping(monitor='val_loss', patience=10, # Possibly more patience for final run\n",
    "                                                  restore_best_weights=True, verbose=1)\n",
    "\n",
    "             # Train the final model\n",
    "             history = final_model.fit(\n",
    "                 X_train, y_train,\n",
    "                 epochs=FINAL_EPOCHS, # Use potentially more epochs for final training\n",
    "                 batch_size=BATCH_SIZE,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[final_early_stopping],\n",
    "                 verbose=1\n",
    "             )\n",
    "             print(\"Final model training finished.\")\n",
    "\n",
    "\n",
    "    # --- 7. Evaluate FINAL Model on Validation Set ---\n",
    "    if final_model is not None and scaler is not None and 'X_val' in locals() and X_val.shape[0] > 0:\n",
    "        print(f\"\\n--- Evaluating FINAL Tuned LSTM Model on {VALIDATION_YEAR} Validation Data ---\")\n",
    "        print(\"Predicting...\")\n",
    "        predictions_scaled = final_model.predict(X_val)\n",
    "\n",
    "        print(\"Inverse transforming...\")\n",
    "        try:\n",
    "             predictions_inv = scaler.inverse_transform(predictions_scaled)\n",
    "             actuals_inv = y_val_actual_unscaled # Stored earlier\n",
    "\n",
    "             # Align lengths if necessary (e.g., if prediction output length differs slightly)\n",
    "             min_len_eval = min(len(actuals_inv), len(predictions_inv))\n",
    "             if len(actuals_inv) != len(predictions_inv):\n",
    "                 print(f\"Warning: Length mismatch final eval. Truncating to {min_len_eval}.\")\n",
    "             actuals_inv = actuals_inv[:min_len_eval]\n",
    "             predictions_inv = predictions_inv[:min_len_eval]\n",
    "             dates_val_plot = dates_val_for_plotting[:min_len_eval]\n",
    "\n",
    "             # Calculate metrics\n",
    "             if len(actuals_inv) > 0:\n",
    "                 r2_val, mae_val, mse_val = calculate_metrics(actuals_inv, predictions_inv)\n",
    "                 print(f\"FINAL Tuned Validation R-squared (R2): {r2_val:.4f}\")\n",
    "                 print(f\"FINAL Tuned Validation Mean Absolute Error (MAE): {mae_val:.2f}\")\n",
    "                 print(f\"FINAL Tuned Validation Mean Squared Error (MSE): {mse_val:.2f}\")\n",
    "\n",
    "                 # --- 8. Plot Validation Results ---\n",
    "                 print(f\"\\n--- Plotting FINAL Validation Results for {PRIMARY_TARGET} (Actual vs. Predicted {VALIDATION_YEAR}) ---\")\n",
    "                 plot_title_val = f'TUNED LSTM Validation (Nashik/Wheat): {PRIMARY_TARGET.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()} Price (Actual vs. Predicted {VALIDATION_YEAR})'\n",
    "                 fig_val = plot_lstm_validation_results(dates_val_plot, actuals_inv, predictions_inv, PRIMARY_TARGET, plot_title_val)\n",
    "                 fig_val.show()\n",
    "             else: print(\"Skipping metrics/plotting: No valid aligned data.\")\n",
    "        except Exception as e: print(f\"Error during final prediction/scaling/eval: {e}\"); traceback.print_exc()\n",
    "    elif final_model is None: print(\"\\nSkipping final evaluation (Model not trained).\")\n",
    "    else: print(\"\\nCannot proceed: lack of data after filtering/sequencing.\")\n",
    "else: print(\"\\nFailed: check data loading, preprocessing, or mapping lookup.\")\n",
    "\n",
    "print(\"\\nProcess finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1075e82",
   "metadata": {},
   "source": [
    "# new iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67f87cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LSTM Forecasting & Validation with KerasTuner ---\n",
      "--- (Nashik/Wheat: 2002-2023 Train, 2024 Validate) ---\n",
      "------------------------------\n",
      "Processing Training (2002-2023) Dataset\n",
      "------------------------------\n",
      "Loading Training (2002-2023) data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_2002_2023.csv...\n",
      "Loaded 6246 rows.\n",
      "Constructing 'full_date'...\n",
      "6246 rows after date construction.\n",
      "6246 rows after ensuring price columns numeric.\n",
      "Training (2002-2023) base data loaded. 6246 rows.\n",
      "------------------------------\n",
      "Processing Validation (2024) Dataset\n",
      "------------------------------\n",
      "Loading Validation (2024) data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_test_2024.csv...\n",
      "Loaded 278 rows.\n",
      "Constructing 'full_date'...\n",
      "278 rows after date construction.\n",
      "278 rows after ensuring price columns numeric.\n",
      "Validation (2024) base data loaded. 278 rows.\n",
      "\n",
      "Selected: Maharashtra/Nashik/Wheat -> Encoded: St=6291, Di=6291, Co=6291\n",
      "\n",
      "Filtering datasets using encoded values...\n",
      "\n",
      "Preparing data for LSTM (Target: avg_modal_price)...\n",
      "Creating sequences with length 60...\n",
      "Training sequences shape: X=(6186, 60, 1), y=(6186, 1)\n",
      "Validation sequences shape: X=(218, 60, 1), y=(218, 1)\n",
      "\n",
      "Starting KerasTuner hyperparameter search...\n",
      "Running KerasTuner search for 20 trials...\n",
      "\n",
      "Hyperparameter search finished.\n",
      "Results summary\n",
      "Results in keras_tuner_dir\\lstm_wheat_price_tuning\n",
      "Showing 1 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "dropout: 0.1\n",
      "learning_rate: 0.0001\n",
      "Score: 0.0021314695477485657\n",
      "\n",
      "The hyperparameter search is complete. The optimal hyperparameters found are:\n",
      "- Units: 128\n",
      "- Dropout: 0.10\n",
      "- Learning Rate: 0.0001\n",
      "                \n",
      "\n",
      "Building and training final model with best hyperparameters...\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 12s 48ms/step - loss: 0.0608 - val_loss: 0.0166\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 9s 44ms/step - loss: 0.0020 - val_loss: 0.0084\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 9s 45ms/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 9s 47ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 9s 47ms/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 9s 45ms/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 9s 47ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 9s 49ms/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 9s 46ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 9s 48ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 9s 49ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 9s 46ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 9s 48ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 9s 46ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - ETA: 0s - loss: 0.0015Restoring model weights from the end of the best epoch: 5.\n",
      "194/194 [==============================] - 9s 49ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 15: early stopping\n",
      "Final model training finished.\n",
      "\n",
      "--- Evaluating FINAL Tuned LSTM Model on 2024 Validation Data ---\n",
      "Predicting...\n",
      "7/7 [==============================] - 0s 19ms/step\n",
      "Inverse transforming...\n",
      "FINAL Tuned Validation R-squared (R2): 0.6410\n",
      "FINAL Tuned Validation Mean Absolute Error (MAE): 74.51\n",
      "FINAL Tuned Validation Mean Squared Error (MSE): 9471.94\n",
      "\n",
      "--- Plotting FINAL Validation Results for avg_modal_price (Actual vs. Predicted 2024) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "blue"
         },
         "marker": {
          "size": 4
         },
         "mode": "lines+markers",
         "name": "Actual Modal (2024)",
         "type": "scatter",
         "x": [
          "2024-03-14T00:00:00.000000000",
          "2024-03-15T00:00:00.000000000",
          "2024-03-16T00:00:00.000000000",
          "2024-03-18T00:00:00.000000000",
          "2024-03-19T00:00:00.000000000",
          "2024-03-20T00:00:00.000000000",
          "2024-03-21T00:00:00.000000000",
          "2024-03-22T00:00:00.000000000",
          "2024-03-23T00:00:00.000000000",
          "2024-03-25T00:00:00.000000000",
          "2024-03-26T00:00:00.000000000",
          "2024-03-27T00:00:00.000000000",
          "2024-03-28T00:00:00.000000000",
          "2024-03-29T00:00:00.000000000",
          "2024-04-03T00:00:00.000000000",
          "2024-04-04T00:00:00.000000000",
          "2024-04-05T00:00:00.000000000",
          "2024-04-08T00:00:00.000000000",
          "2024-04-13T00:00:00.000000000",
          "2024-04-15T00:00:00.000000000",
          "2024-04-19T00:00:00.000000000",
          "2024-04-22T00:00:00.000000000",
          "2024-04-24T00:00:00.000000000",
          "2024-04-25T00:00:00.000000000",
          "2024-04-26T00:00:00.000000000",
          "2024-04-27T00:00:00.000000000",
          "2024-04-29T00:00:00.000000000",
          "2024-04-30T00:00:00.000000000",
          "2024-05-02T00:00:00.000000000",
          "2024-05-03T00:00:00.000000000",
          "2024-05-04T00:00:00.000000000",
          "2024-05-06T00:00:00.000000000",
          "2024-05-07T00:00:00.000000000",
          "2024-05-08T00:00:00.000000000",
          "2024-05-09T00:00:00.000000000",
          "2024-05-10T00:00:00.000000000",
          "2024-05-11T00:00:00.000000000",
          "2024-05-13T00:00:00.000000000",
          "2024-05-14T00:00:00.000000000",
          "2024-05-15T00:00:00.000000000",
          "2024-05-16T00:00:00.000000000",
          "2024-05-17T00:00:00.000000000",
          "2024-05-18T00:00:00.000000000",
          "2024-05-21T00:00:00.000000000",
          "2024-05-22T00:00:00.000000000",
          "2024-05-23T00:00:00.000000000",
          "2024-05-24T00:00:00.000000000",
          "2024-05-25T00:00:00.000000000",
          "2024-05-27T00:00:00.000000000",
          "2024-05-28T00:00:00.000000000",
          "2024-05-29T00:00:00.000000000",
          "2024-05-30T00:00:00.000000000",
          "2024-05-31T00:00:00.000000000",
          "2024-06-01T00:00:00.000000000",
          "2024-06-03T00:00:00.000000000",
          "2024-06-04T00:00:00.000000000",
          "2024-06-05T00:00:00.000000000",
          "2024-06-06T00:00:00.000000000",
          "2024-06-07T00:00:00.000000000",
          "2024-06-08T00:00:00.000000000",
          "2024-06-10T00:00:00.000000000",
          "2024-06-11T00:00:00.000000000",
          "2024-06-12T00:00:00.000000000",
          "2024-06-13T00:00:00.000000000",
          "2024-06-14T00:00:00.000000000",
          "2024-06-15T00:00:00.000000000",
          "2024-06-17T00:00:00.000000000",
          "2024-06-18T00:00:00.000000000",
          "2024-06-19T00:00:00.000000000",
          "2024-06-20T00:00:00.000000000",
          "2024-06-21T00:00:00.000000000",
          "2024-06-22T00:00:00.000000000",
          "2024-06-24T00:00:00.000000000",
          "2024-06-25T00:00:00.000000000",
          "2024-06-26T00:00:00.000000000",
          "2024-06-27T00:00:00.000000000",
          "2024-06-28T00:00:00.000000000",
          "2024-06-29T00:00:00.000000000",
          "2024-07-01T00:00:00.000000000",
          "2024-07-02T00:00:00.000000000",
          "2024-07-03T00:00:00.000000000",
          "2024-07-04T00:00:00.000000000",
          "2024-07-05T00:00:00.000000000",
          "2024-07-06T00:00:00.000000000",
          "2024-07-08T00:00:00.000000000",
          "2024-07-09T00:00:00.000000000",
          "2024-07-10T00:00:00.000000000",
          "2024-07-11T00:00:00.000000000",
          "2024-07-12T00:00:00.000000000",
          "2024-07-13T00:00:00.000000000",
          "2024-07-15T00:00:00.000000000",
          "2024-07-16T00:00:00.000000000",
          "2024-07-17T00:00:00.000000000",
          "2024-07-18T00:00:00.000000000",
          "2024-07-19T00:00:00.000000000",
          "2024-07-20T00:00:00.000000000",
          "2024-07-22T00:00:00.000000000",
          "2024-07-23T00:00:00.000000000",
          "2024-07-24T00:00:00.000000000",
          "2024-07-25T00:00:00.000000000",
          "2024-07-26T00:00:00.000000000",
          "2024-07-27T00:00:00.000000000",
          "2024-07-29T00:00:00.000000000",
          "2024-07-30T00:00:00.000000000",
          "2024-07-31T00:00:00.000000000",
          "2024-08-05T00:00:00.000000000",
          "2024-08-06T00:00:00.000000000",
          "2024-08-07T00:00:00.000000000",
          "2024-08-08T00:00:00.000000000",
          "2024-08-09T00:00:00.000000000",
          "2024-08-10T00:00:00.000000000",
          "2024-08-12T00:00:00.000000000",
          "2024-08-14T00:00:00.000000000",
          "2024-08-16T00:00:00.000000000",
          "2024-08-17T00:00:00.000000000",
          "2024-08-19T00:00:00.000000000",
          "2024-08-20T00:00:00.000000000",
          "2024-08-21T00:00:00.000000000",
          "2024-08-22T00:00:00.000000000",
          "2024-08-23T00:00:00.000000000",
          "2024-08-24T00:00:00.000000000",
          "2024-08-26T00:00:00.000000000",
          "2024-08-27T00:00:00.000000000",
          "2024-08-28T00:00:00.000000000",
          "2024-08-29T00:00:00.000000000",
          "2024-08-30T00:00:00.000000000",
          "2024-08-31T00:00:00.000000000",
          "2024-09-03T00:00:00.000000000",
          "2024-09-04T00:00:00.000000000",
          "2024-09-05T00:00:00.000000000",
          "2024-09-06T00:00:00.000000000",
          "2024-09-07T00:00:00.000000000",
          "2024-09-09T00:00:00.000000000",
          "2024-09-10T00:00:00.000000000",
          "2024-09-11T00:00:00.000000000",
          "2024-09-12T00:00:00.000000000",
          "2024-09-13T00:00:00.000000000",
          "2024-09-14T00:00:00.000000000",
          "2024-09-16T00:00:00.000000000",
          "2024-09-17T00:00:00.000000000",
          "2024-09-18T00:00:00.000000000",
          "2024-09-19T00:00:00.000000000",
          "2024-09-20T00:00:00.000000000",
          "2024-09-21T00:00:00.000000000",
          "2024-09-23T00:00:00.000000000",
          "2024-09-24T00:00:00.000000000",
          "2024-09-26T00:00:00.000000000",
          "2024-09-27T00:00:00.000000000",
          "2024-09-28T00:00:00.000000000",
          "2024-09-30T00:00:00.000000000",
          "2024-10-01T00:00:00.000000000",
          "2024-10-02T00:00:00.000000000",
          "2024-10-03T00:00:00.000000000",
          "2024-10-04T00:00:00.000000000",
          "2024-10-05T00:00:00.000000000",
          "2024-10-09T00:00:00.000000000",
          "2024-10-10T00:00:00.000000000",
          "2024-10-11T00:00:00.000000000",
          "2024-10-12T00:00:00.000000000",
          "2024-10-14T00:00:00.000000000",
          "2024-10-15T00:00:00.000000000",
          "2024-10-16T00:00:00.000000000",
          "2024-10-17T00:00:00.000000000",
          "2024-10-18T00:00:00.000000000",
          "2024-10-19T00:00:00.000000000",
          "2024-10-21T00:00:00.000000000",
          "2024-10-22T00:00:00.000000000",
          "2024-10-23T00:00:00.000000000",
          "2024-10-24T00:00:00.000000000",
          "2024-10-25T00:00:00.000000000",
          "2024-10-26T00:00:00.000000000",
          "2024-10-28T00:00:00.000000000",
          "2024-10-29T00:00:00.000000000",
          "2024-11-04T00:00:00.000000000",
          "2024-11-05T00:00:00.000000000",
          "2024-11-07T00:00:00.000000000",
          "2024-11-08T00:00:00.000000000",
          "2024-11-09T00:00:00.000000000",
          "2024-11-11T00:00:00.000000000",
          "2024-11-13T00:00:00.000000000",
          "2024-11-14T00:00:00.000000000",
          "2024-11-15T00:00:00.000000000",
          "2024-11-16T00:00:00.000000000",
          "2024-11-18T00:00:00.000000000",
          "2024-11-19T00:00:00.000000000",
          "2024-11-22T00:00:00.000000000",
          "2024-11-23T00:00:00.000000000",
          "2024-11-25T00:00:00.000000000",
          "2024-11-26T00:00:00.000000000",
          "2024-11-27T00:00:00.000000000",
          "2024-11-28T00:00:00.000000000",
          "2024-11-30T00:00:00.000000000",
          "2024-12-02T00:00:00.000000000",
          "2024-12-03T00:00:00.000000000",
          "2024-12-04T00:00:00.000000000",
          "2024-12-05T00:00:00.000000000",
          "2024-12-06T00:00:00.000000000",
          "2024-12-07T00:00:00.000000000",
          "2024-12-09T00:00:00.000000000",
          "2024-12-10T00:00:00.000000000",
          "2024-12-11T00:00:00.000000000",
          "2024-12-12T00:00:00.000000000",
          "2024-12-13T00:00:00.000000000",
          "2024-12-14T00:00:00.000000000",
          "2024-12-16T00:00:00.000000000",
          "2024-12-17T00:00:00.000000000",
          "2024-12-18T00:00:00.000000000",
          "2024-12-19T00:00:00.000000000",
          "2024-12-20T00:00:00.000000000",
          "2024-12-21T00:00:00.000000000",
          "2024-12-23T00:00:00.000000000",
          "2024-12-24T00:00:00.000000000",
          "2024-12-25T00:00:00.000000000",
          "2024-12-26T00:00:00.000000000",
          "2024-12-27T00:00:00.000000000",
          "2024-12-28T00:00:00.000000000",
          "2024-12-30T00:00:00.000000000",
          "2024-12-31T00:00:00.000000000"
         ],
         "y": {
          "bdata": "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",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "color": "red"
         },
         "mode": "lines",
         "name": "Predicted Modal (2024)",
         "type": "scatter",
         "x": [
          "2024-03-14T00:00:00.000000000",
          "2024-03-15T00:00:00.000000000",
          "2024-03-16T00:00:00.000000000",
          "2024-03-18T00:00:00.000000000",
          "2024-03-19T00:00:00.000000000",
          "2024-03-20T00:00:00.000000000",
          "2024-03-21T00:00:00.000000000",
          "2024-03-22T00:00:00.000000000",
          "2024-03-23T00:00:00.000000000",
          "2024-03-25T00:00:00.000000000",
          "2024-03-26T00:00:00.000000000",
          "2024-03-27T00:00:00.000000000",
          "2024-03-28T00:00:00.000000000",
          "2024-03-29T00:00:00.000000000",
          "2024-04-03T00:00:00.000000000",
          "2024-04-04T00:00:00.000000000",
          "2024-04-05T00:00:00.000000000",
          "2024-04-08T00:00:00.000000000",
          "2024-04-13T00:00:00.000000000",
          "2024-04-15T00:00:00.000000000",
          "2024-04-19T00:00:00.000000000",
          "2024-04-22T00:00:00.000000000",
          "2024-04-24T00:00:00.000000000",
          "2024-04-25T00:00:00.000000000",
          "2024-04-26T00:00:00.000000000",
          "2024-04-27T00:00:00.000000000",
          "2024-04-29T00:00:00.000000000",
          "2024-04-30T00:00:00.000000000",
          "2024-05-02T00:00:00.000000000",
          "2024-05-03T00:00:00.000000000",
          "2024-05-04T00:00:00.000000000",
          "2024-05-06T00:00:00.000000000",
          "2024-05-07T00:00:00.000000000",
          "2024-05-08T00:00:00.000000000",
          "2024-05-09T00:00:00.000000000",
          "2024-05-10T00:00:00.000000000",
          "2024-05-11T00:00:00.000000000",
          "2024-05-13T00:00:00.000000000",
          "2024-05-14T00:00:00.000000000",
          "2024-05-15T00:00:00.000000000",
          "2024-05-16T00:00:00.000000000",
          "2024-05-17T00:00:00.000000000",
          "2024-05-18T00:00:00.000000000",
          "2024-05-21T00:00:00.000000000",
          "2024-05-22T00:00:00.000000000",
          "2024-05-23T00:00:00.000000000",
          "2024-05-24T00:00:00.000000000",
          "2024-05-25T00:00:00.000000000",
          "2024-05-27T00:00:00.000000000",
          "2024-05-28T00:00:00.000000000",
          "2024-05-29T00:00:00.000000000",
          "2024-05-30T00:00:00.000000000",
          "2024-05-31T00:00:00.000000000",
          "2024-06-01T00:00:00.000000000",
          "2024-06-03T00:00:00.000000000",
          "2024-06-04T00:00:00.000000000",
          "2024-06-05T00:00:00.000000000",
          "2024-06-06T00:00:00.000000000",
          "2024-06-07T00:00:00.000000000",
          "2024-06-08T00:00:00.000000000",
          "2024-06-10T00:00:00.000000000",
          "2024-06-11T00:00:00.000000000",
          "2024-06-12T00:00:00.000000000",
          "2024-06-13T00:00:00.000000000",
          "2024-06-14T00:00:00.000000000",
          "2024-06-15T00:00:00.000000000",
          "2024-06-17T00:00:00.000000000",
          "2024-06-18T00:00:00.000000000",
          "2024-06-19T00:00:00.000000000",
          "2024-06-20T00:00:00.000000000",
          "2024-06-21T00:00:00.000000000",
          "2024-06-22T00:00:00.000000000",
          "2024-06-24T00:00:00.000000000",
          "2024-06-25T00:00:00.000000000",
          "2024-06-26T00:00:00.000000000",
          "2024-06-27T00:00:00.000000000",
          "2024-06-28T00:00:00.000000000",
          "2024-06-29T00:00:00.000000000",
          "2024-07-01T00:00:00.000000000",
          "2024-07-02T00:00:00.000000000",
          "2024-07-03T00:00:00.000000000",
          "2024-07-04T00:00:00.000000000",
          "2024-07-05T00:00:00.000000000",
          "2024-07-06T00:00:00.000000000",
          "2024-07-08T00:00:00.000000000",
          "2024-07-09T00:00:00.000000000",
          "2024-07-10T00:00:00.000000000",
          "2024-07-11T00:00:00.000000000",
          "2024-07-12T00:00:00.000000000",
          "2024-07-13T00:00:00.000000000",
          "2024-07-15T00:00:00.000000000",
          "2024-07-16T00:00:00.000000000",
          "2024-07-17T00:00:00.000000000",
          "2024-07-18T00:00:00.000000000",
          "2024-07-19T00:00:00.000000000",
          "2024-07-20T00:00:00.000000000",
          "2024-07-22T00:00:00.000000000",
          "2024-07-23T00:00:00.000000000",
          "2024-07-24T00:00:00.000000000",
          "2024-07-25T00:00:00.000000000",
          "2024-07-26T00:00:00.000000000",
          "2024-07-27T00:00:00.000000000",
          "2024-07-29T00:00:00.000000000",
          "2024-07-30T00:00:00.000000000",
          "2024-07-31T00:00:00.000000000",
          "2024-08-05T00:00:00.000000000",
          "2024-08-06T00:00:00.000000000",
          "2024-08-07T00:00:00.000000000",
          "2024-08-08T00:00:00.000000000",
          "2024-08-09T00:00:00.000000000",
          "2024-08-10T00:00:00.000000000",
          "2024-08-12T00:00:00.000000000",
          "2024-08-14T00:00:00.000000000",
          "2024-08-16T00:00:00.000000000",
          "2024-08-17T00:00:00.000000000",
          "2024-08-19T00:00:00.000000000",
          "2024-08-20T00:00:00.000000000",
          "2024-08-21T00:00:00.000000000",
          "2024-08-22T00:00:00.000000000",
          "2024-08-23T00:00:00.000000000",
          "2024-08-24T00:00:00.000000000",
          "2024-08-26T00:00:00.000000000",
          "2024-08-27T00:00:00.000000000",
          "2024-08-28T00:00:00.000000000",
          "2024-08-29T00:00:00.000000000",
          "2024-08-30T00:00:00.000000000",
          "2024-08-31T00:00:00.000000000",
          "2024-09-03T00:00:00.000000000",
          "2024-09-04T00:00:00.000000000",
          "2024-09-05T00:00:00.000000000",
          "2024-09-06T00:00:00.000000000",
          "2024-09-07T00:00:00.000000000",
          "2024-09-09T00:00:00.000000000",
          "2024-09-10T00:00:00.000000000",
          "2024-09-11T00:00:00.000000000",
          "2024-09-12T00:00:00.000000000",
          "2024-09-13T00:00:00.000000000",
          "2024-09-14T00:00:00.000000000",
          "2024-09-16T00:00:00.000000000",
          "2024-09-17T00:00:00.000000000",
          "2024-09-18T00:00:00.000000000",
          "2024-09-19T00:00:00.000000000",
          "2024-09-20T00:00:00.000000000",
          "2024-09-21T00:00:00.000000000",
          "2024-09-23T00:00:00.000000000",
          "2024-09-24T00:00:00.000000000",
          "2024-09-26T00:00:00.000000000",
          "2024-09-27T00:00:00.000000000",
          "2024-09-28T00:00:00.000000000",
          "2024-09-30T00:00:00.000000000",
          "2024-10-01T00:00:00.000000000",
          "2024-10-02T00:00:00.000000000",
          "2024-10-03T00:00:00.000000000",
          "2024-10-04T00:00:00.000000000",
          "2024-10-05T00:00:00.000000000",
          "2024-10-09T00:00:00.000000000",
          "2024-10-10T00:00:00.000000000",
          "2024-10-11T00:00:00.000000000",
          "2024-10-12T00:00:00.000000000",
          "2024-10-14T00:00:00.000000000",
          "2024-10-15T00:00:00.000000000",
          "2024-10-16T00:00:00.000000000",
          "2024-10-17T00:00:00.000000000",
          "2024-10-18T00:00:00.000000000",
          "2024-10-19T00:00:00.000000000",
          "2024-10-21T00:00:00.000000000",
          "2024-10-22T00:00:00.000000000",
          "2024-10-23T00:00:00.000000000",
          "2024-10-24T00:00:00.000000000",
          "2024-10-25T00:00:00.000000000",
          "2024-10-26T00:00:00.000000000",
          "2024-10-28T00:00:00.000000000",
          "2024-10-29T00:00:00.000000000",
          "2024-11-04T00:00:00.000000000",
          "2024-11-05T00:00:00.000000000",
          "2024-11-07T00:00:00.000000000",
          "2024-11-08T00:00:00.000000000",
          "2024-11-09T00:00:00.000000000",
          "2024-11-11T00:00:00.000000000",
          "2024-11-13T00:00:00.000000000",
          "2024-11-14T00:00:00.000000000",
          "2024-11-15T00:00:00.000000000",
          "2024-11-16T00:00:00.000000000",
          "2024-11-18T00:00:00.000000000",
          "2024-11-19T00:00:00.000000000",
          "2024-11-22T00:00:00.000000000",
          "2024-11-23T00:00:00.000000000",
          "2024-11-25T00:00:00.000000000",
          "2024-11-26T00:00:00.000000000",
          "2024-11-27T00:00:00.000000000",
          "2024-11-28T00:00:00.000000000",
          "2024-11-30T00:00:00.000000000",
          "2024-12-02T00:00:00.000000000",
          "2024-12-03T00:00:00.000000000",
          "2024-12-04T00:00:00.000000000",
          "2024-12-05T00:00:00.000000000",
          "2024-12-06T00:00:00.000000000",
          "2024-12-07T00:00:00.000000000",
          "2024-12-09T00:00:00.000000000",
          "2024-12-10T00:00:00.000000000",
          "2024-12-11T00:00:00.000000000",
          "2024-12-12T00:00:00.000000000",
          "2024-12-13T00:00:00.000000000",
          "2024-12-14T00:00:00.000000000",
          "2024-12-16T00:00:00.000000000",
          "2024-12-17T00:00:00.000000000",
          "2024-12-18T00:00:00.000000000",
          "2024-12-19T00:00:00.000000000",
          "2024-12-20T00:00:00.000000000",
          "2024-12-21T00:00:00.000000000",
          "2024-12-23T00:00:00.000000000",
          "2024-12-24T00:00:00.000000000",
          "2024-12-25T00:00:00.000000000",
          "2024-12-26T00:00:00.000000000",
          "2024-12-27T00:00:00.000000000",
          "2024-12-28T00:00:00.000000000",
          "2024-12-30T00:00:00.000000000",
          "2024-12-31T00:00:00.000000000"
         ],
         "y": {
          "bdata": "+Y4hRfKlIUXCdyFFeWkhRZdfIUUAgyFFeyghRd4jIUX8SSFFcDwhRUYwIUWagyFFVUwhRQ1GIUVoGyFFKuwgRRggIUX/KiFFywMhReNBIUX7jCFF8OIhRYqkIUWe8yFFs8wiRaMJI0XxBSNFgD4jRUujI0WGgCNFjFUkRdY9JEXZ9CNFRs4jRZUUI0VeFiNF2mYkRdjNJEXj3SRF2m4kRQ15JEVVRSRFl7wjRaBNI0UkJCNFuhcjRZigIkXlZSJFPPshRQA1IkUWKCJFeDwiRR6cIkVtxSJFZyEjRWJMI0WqDSNFfWAjRVTGI0UOtiNFpFwjRZlGI0VjwCJFnjAjRciOI0WbzSNFGUEjRbANI0VjcyNFYmgjRUfRI0W2mCRFWRIkRTBNJEUI6CRF1AElRUtKJUWpuSVFThsmRRSXJkVxgSZFQSonRZsnJ0U/1yZF6HknRTPvJ0XKsShFTXcpRdp3KkUtFCtFZwAqRbPHKUVEDSpFE+YpRem4KUV79ClFquspRcKWKUXw8ylF/hcqRTVNKkVWOypFQhwqRYj/KUX4OSpFUkgqRYU6KkWMOypFUHoqRZvdKkXwqCpFnjoqReKBKkXcdypFLHYqRUcMK0V76CpF6eYqRdmKKkVeYCpF8PUpRQm7KUXO+SlFODsqRfpUKkVv3CpFsGcrRVHtK0X86ytFL4MsRSrbLEU56ixFDmQsRYZ0LEXSxSxFwyItRbtYLkUpPy9F5WYvRRcxMEXDjjBFD8YwRTMpMUW14jBFvzowRVdBMEWZCjBFmfkvRb2yL0VoHS9FfLUuRUEtLkWoci5FcI4uRTbZLkWrli9FEMYvRdnpL0UMri9FK78vRSw5MEVgbDBFzTIxRYSRMUX/YTJFjeUzRVwYNEU7HzVFOB02RaRLN0UfnDdFnv83RZVoOEWioDhFur05RchxOkXVYztFouo7RV1iPEWloDxFCgo9RUHfPUVMlD1FOSs+RZysPkV+HT9FuU8/RQyQPkWxuT5FoaM+RbStPkUd/j1FApk8RcWuO0VB9DpFU0w6RdWqOUWWpzhFmHY4RTVzOEVVKDhF9uw3RYDyN0WVrjdFOko3RToZN0W8CDdFmik3RQLgN0V7JDhFkso4RbxAOUWWMDpF+O85Rb07OkUMrTlFQ5w5RS8SOUU=",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "hovermode": "x unified",
        "legend": {
         "title": {
          "text": "Legend"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "TUNED LSTM Validation (Nashik/Wheat): Modal Price (Actual vs. Predicted 2024)"
        },
        "xaxis": {
         "title": {
          "text": "Date (2024)"
         }
        },
        "yaxis": {
         "title": {
          "text": "Price (Modal)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process finished.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow keras-tuner pandas numpy plotly scikit-learn ipython # Uncomment if needed\n",
    "\n",
    "# --- Standard Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display\n",
    "import traceback\n",
    "import warnings\n",
    "import os\n",
    "import plotly.graph_objects as go # Moved import here\n",
    "\n",
    "# --- Keras / TensorFlow Imports ---\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam # <--- Using standard TF Keras path\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Suppress common warnings & TF logs\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TensorFlow INFO messages\n",
    "# tf.random.set_seed(42) # Optional reproducibility\n",
    "# np.random.seed(42)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Data Paths\n",
    "DATA_PATH_TRAIN = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_2002_2023.csv\"\n",
    "DATA_PATH_VALIDATION = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_nashik_test_2024.csv\"\n",
    "\n",
    "# Target Columns & Date Construction Columns\n",
    "TARGET_COLUMNS = ['avg_min_price', 'avg_max_price', 'avg_modal_price']\n",
    "PRIMARY_TARGET = 'avg_modal_price' # Focus on one target\n",
    "DATE_COLUMN = 'full_date'; YEAR_COL = 'year'; MONTH_COL = 'month'; DAY_COL = 'date'\n",
    "VALIDATION_YEAR = 2024\n",
    "\n",
    "# Filter Selections\n",
    "SELECTED_STATE_STR = \"Maharashtra\"; SELECTED_DISTRICT_STR = \"Nashik\"; SELECTED_COMMODITY_STR = \"Wheat\"\n",
    "\n",
    "# Frequency Encoding Maps (CONFIRM THESE ARE CORRECT)\n",
    "state_name_encoding_map = {\"maharashtra\": 6291}\n",
    "district_name_encoding_map = {\"nashik\": 6291}\n",
    "commodity_name_encoding_map = {\"wheat\": 6291}\n",
    "\n",
    "# --- LSTM & Tuner Configuration ---\n",
    "SEQUENCE_LENGTH = 60     # Number of past days - Keep fixed during tuning for simplicity\n",
    "KERAS_TUNER_MAX_TRIALS = 20 # How many different hyperparameter sets to try\n",
    "KERAS_TUNER_EXECUTIONS = 2  # How many times to train each set (for stability)\n",
    "KERAS_TUNER_PROJECT_NAME = 'lstm_wheat_price_tuning' # Folder to save results\n",
    "SEARCH_EPOCHS = 20          # Max epochs *per trial* during search (EarlyStopping recommended)\n",
    "FINAL_EPOCHS = 100         # Max epochs for training the *final* best model\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def remove_outliers_iqr(df, columns_to_check):\n",
    "    \"\"\"Removes outliers from specified numerical columns using the IQR method.\"\"\"\n",
    "    df_filtered = df.copy(); initial_rows = len(df_filtered)\n",
    "    valid_columns = [col for col in columns_to_check if col in df_filtered.columns and pd.api.types.is_numeric_dtype(df_filtered[col])]\n",
    "    if not valid_columns: return df_filtered\n",
    "    subset_for_iqr = df_filtered[valid_columns]\n",
    "    Q1 = subset_for_iqr.quantile(0.25); Q3 = subset_for_iqr.quantile(0.75); IQR = Q3 - Q1\n",
    "    mask = ~((subset_for_iqr < (Q1 - 1.5 * IQR)) | (subset_for_iqr > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    df_filtered = df_filtered[mask]; rows_removed = initial_rows - len(df_filtered)\n",
    "    if rows_removed > 0: print(f\"Removed {rows_removed} rows via IQR.\")\n",
    "    return df_filtered\n",
    "\n",
    "def load_and_preprocess_base_data(path, date_col_name, year_col, month_col, day_col, all_potential_targets, dataset_name=\"Training\"):\n",
    "    \"\"\"Loads data, constructs date, basic cleaning. Returns essential cols.\"\"\"\n",
    "    print(\"-\" * 30); print(f\"Processing {dataset_name} Dataset\"); print(\"-\" * 30)\n",
    "    try:\n",
    "        print(f\"Loading {dataset_name} data from {path}...\"); df = pd.read_csv(path); print(f\"Loaded {len(df)} rows.\")\n",
    "        # 1. Construct Date\n",
    "        date_components_cols = [year_col, month_col, day_col]\n",
    "        if not all(col in df.columns for col in date_components_cols): print(f\"Error: Date component cols missing: {[c for c in date_components_cols if c not in df.columns]}\"); return None\n",
    "        for col in date_components_cols: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=date_components_cols, inplace=True)\n",
    "        print(f\"Constructing '{date_col_name}'...\");\n",
    "        df[date_col_name] = pd.to_datetime({'year': df[year_col], 'month': df[month_col], 'day': df[day_col]}, errors='coerce')\n",
    "        initial_rows_date = len(df); df.dropna(subset=[date_col_name], inplace=True)\n",
    "        if initial_rows_date > len(df): print(f\"Dropped {initial_rows_date - len(df)} rows due to invalid date components.\")\n",
    "        print(f\"{len(df)} rows after date construction.\")\n",
    "        # 2. Keep ONLY necessary columns\n",
    "        required_numeric_filter_cols = ['state_name', 'district_name', 'commodity_name']\n",
    "        keep_cols = [date_col_name] + all_potential_targets + required_numeric_filter_cols\n",
    "        missing_req_cols = [col for col in keep_cols if col not in df.columns]\n",
    "        if missing_req_cols: print(f\"Error: Required columns missing: {missing_req_cols}\"); print(f\"Available: {df.columns.tolist()}\"); return None\n",
    "        df = df[keep_cols]\n",
    "        # 3. Ensure Price/Target columns are numeric\n",
    "        for col in all_potential_targets: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df.dropna(subset=all_potential_targets, how='any', inplace=True)\n",
    "        print(f\"{len(df)} rows after ensuring price columns numeric.\")\n",
    "        # 4. Ensure Filter columns are numeric\n",
    "        for col in required_numeric_filter_cols:\n",
    "             if not pd.api.types.is_numeric_dtype(df[col]): print(f\"Error: Col '{col}' expected numeric but isn't.\"); return None\n",
    "        # 5. Apply IQR Outlier Removal (Optional)\n",
    "        # df = remove_outliers_iqr(df, all_potential_targets)\n",
    "        df.sort_values(date_col_name, inplace=True)\n",
    "        print(f\"{dataset_name} base data loaded. {len(df)} rows.\")\n",
    "        return df\n",
    "    except FileNotFoundError: print(f\"Error: {dataset_name} file not found at {path}\"); return None\n",
    "    except Exception as e: print(f\"Error loading/preprocessing {dataset_name}: {e}\"); traceback.print_exc(); return None\n",
    "\n",
    "def create_sequences(data, sequence_length):\n",
    "    \"\"\"Creates sequences of data for LSTM.\"\"\"\n",
    "    X, y = [], []\n",
    "    if len(data) <= sequence_length: return np.array(X), np.array(y) # Handle case with insufficient data\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:(i + sequence_length)]) # Sequence of inputs\n",
    "        y.append(data[i + sequence_length])    # Value to predict\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculates R2, MAE, MSE after handling potential NaNs and length mismatches.\"\"\"\n",
    "    y_true = np.array(y_true).flatten(); y_pred = np.array(y_pred).flatten()\n",
    "    valid_mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    y_true = y_true[valid_mask]; y_pred = y_pred[valid_mask]\n",
    "    if len(y_true) == 0: print(\"Warning: No valid points for metric calculation.\"); return np.nan, np.nan, np.nan\n",
    "    try:\n",
    "        r2 = r2_score(y_true, y_pred); mae = mean_absolute_error(y_true, y_pred); mse = mean_squared_error(y_true, y_pred)\n",
    "        return r2, mae, mse\n",
    "    except Exception as e: print(f\"Error calculating metrics: {e}\"); return np.nan, np.nan, np.nan\n",
    "\n",
    "def plot_lstm_validation_results(dates_val, actuals_inv, preds_inv, target_column, title):\n",
    "    \"\"\"Plots actuals vs predictions for validation period.\"\"\"\n",
    "    fig = go.Figure(); target_label = target_column.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()\n",
    "    fig.add_trace(go.Scatter(x=dates_val, y=actuals_inv.flatten(), mode='lines+markers', name=f'Actual {target_label} ({VALIDATION_YEAR})', line=dict(color='blue'), marker=dict(size=4)))\n",
    "    fig.add_trace(go.Scatter(x=dates_val, y=preds_inv.flatten(), mode='lines', name=f'Predicted {target_label} ({VALIDATION_YEAR})', line=dict(color='red')))\n",
    "    fig.update_layout(title=title, xaxis_title=f'Date ({VALIDATION_YEAR})', yaxis_title=f'Price ({target_label})', hovermode=\"x unified\", legend_title_text='Legend')\n",
    "    return fig\n",
    "\n",
    "# --- KerasTuner Model Building Function ---\n",
    "def build_lstm_model(hp):\n",
    "    \"\"\"Builds a compiled LSTM model with hyperparameters defined by KerasTuner.\"\"\"\n",
    "    model = Sequential()\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(LSTM(units=hp_units, activation='relu', input_shape=(SEQUENCE_LENGTH, 1)))\n",
    "    model.add(Dropout(rate=hp_dropout))\n",
    "    model.add(Dense(1)) # Output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_learning_rate), # Adam class used here\n",
    "        loss='mean_squared_error'\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "print(\"--- LSTM Forecasting & Validation with KerasTuner ---\")\n",
    "print(f\"--- (Nashik/Wheat: 2002-2023 Train, {VALIDATION_YEAR} Validate) ---\")\n",
    "\n",
    "# 1. Load Base Data\n",
    "df_train_base = load_and_preprocess_base_data(DATA_PATH_TRAIN, DATE_COLUMN, YEAR_COL, MONTH_COL, DAY_COL, TARGET_COLUMNS, \"Training (2002-2023)\")\n",
    "df_val_base = load_and_preprocess_base_data(DATA_PATH_VALIDATION, DATE_COLUMN, YEAR_COL, MONTH_COL, DAY_COL, TARGET_COLUMNS, f\"Validation ({VALIDATION_YEAR})\")\n",
    "\n",
    "# Init model variable\n",
    "final_model = None\n",
    "scaler = None # Make scaler accessible in global scope of this block\n",
    "\n",
    "if df_train_base is not None and df_val_base is not None:\n",
    "    # 2. Get Encoded Values for Filtering\n",
    "    try:\n",
    "        selected_state_key=SELECTED_STATE_STR.strip().lower(); selected_district_key=SELECTED_DISTRICT_STR.strip().lower(); selected_commodity_key=SELECTED_COMMODITY_STR.strip().lower()\n",
    "        encoded_state = state_name_encoding_map.get(selected_state_key); encoded_district = district_name_encoding_map.get(selected_district_key); encoded_commodity = commodity_name_encoding_map.get(selected_commodity_key)\n",
    "        lookup_failed = False\n",
    "        if encoded_state is None: print(f\"Error: State '{SELECTED_STATE_STR}' missing map.\"); lookup_failed=True\n",
    "        if encoded_district is None: print(f\"Error: District '{SELECTED_DISTRICT_STR}' missing map.\"); lookup_failed=True\n",
    "        if encoded_commodity is None: print(f\"Error: Commodity '{SELECTED_COMMODITY_STR}' missing map.\"); lookup_failed=True\n",
    "        if lookup_failed: print(\"Check maps.\"); df_train_base=df_val_base=None\n",
    "        else: print(f\"\\nSelected: {SELECTED_STATE_STR}/{SELECTED_DISTRICT_STR}/{SELECTED_COMMODITY_STR} -> Encoded: St={encoded_state}, Di={encoded_district}, Co={encoded_commodity}\")\n",
    "    except Exception as e: print(f\"Error mapping lookup: {e}\"); df_train_base = df_val_base = None\n",
    "\n",
    "if df_train_base is not None and df_val_base is not None:\n",
    "    # 3. Filtering Data\n",
    "    print(f\"\\nFiltering datasets using encoded values...\")\n",
    "    filter_cols_num = ['state_name', 'district_name', 'commodity_name']\n",
    "    if not all(col in df_train_base.columns for col in filter_cols_num): print(\"Error: Encoded filter cols missing Training.\"); filtered_df_train = pd.DataFrame()\n",
    "    else: filtered_df_train = df_train_base[(df_train_base['state_name'] == encoded_state) & (df_train_base['district_name'] == encoded_district) & (df_train_base['commodity_name'] == encoded_commodity)].copy(); filtered_df_train.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "    if not all(col in df_val_base.columns for col in filter_cols_num): print(\"Error: Encoded filter cols missing Validation.\"); filtered_df_val = pd.DataFrame()\n",
    "    else: filtered_df_val = df_val_base[(df_val_base['state_name'] == encoded_state) & (df_val_base['district_name'] == encoded_district) & (df_val_base['commodity_name'] == encoded_commodity)].copy(); filtered_df_val.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "\n",
    "    if filtered_df_train.empty: print(\"\\nWarning: No training data after filtering.\")\n",
    "    if filtered_df_val.empty: print(\"\\nWarning: No validation data after filtering.\")\n",
    "\n",
    "    # 4. Prepare Data for LSTM (Target: PRIMARY_TARGET)\n",
    "    if not filtered_df_train.empty and not filtered_df_val.empty:\n",
    "        print(f\"\\nPreparing data for LSTM (Target: {PRIMARY_TARGET})...\")\n",
    "        train_series = filtered_df_train[PRIMARY_TARGET].values.reshape(-1, 1)\n",
    "        val_series = filtered_df_val[PRIMARY_TARGET].values.reshape(-1, 1)\n",
    "        val_dates = filtered_df_val[DATE_COLUMN].values\n",
    "\n",
    "        # Scale data\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1)) # Assign to scaler defined outside loop\n",
    "        scaled_train_data = scaler.fit_transform(train_series)\n",
    "        scaled_val_data = scaler.transform(val_series)\n",
    "\n",
    "        # Create sequences\n",
    "        print(f\"Creating sequences with length {SEQUENCE_LENGTH}...\")\n",
    "        X_train, y_train = create_sequences(scaled_train_data, SEQUENCE_LENGTH)\n",
    "        X_val, y_val = create_sequences(scaled_val_data, SEQUENCE_LENGTH)\n",
    "        dates_val_for_plotting = val_dates[SEQUENCE_LENGTH:]\n",
    "        y_val_actual_unscaled = val_series[SEQUENCE_LENGTH:]\n",
    "\n",
    "        if X_train.shape[0] == 0 or X_val.shape[0] == 0:\n",
    "             print(\"Error: Not enough data to create sequences. Try shorter SEQUENCE_LENGTH or check filters.\")\n",
    "        else:\n",
    "             print(f\"Training sequences shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "             print(f\"Validation sequences shape: X={X_val.shape}, y={y_val.shape}\")\n",
    "\n",
    "             # --- 5. Hyperparameter Tuning with KerasTuner ---\n",
    "             print(\"\\nStarting KerasTuner hyperparameter search...\")\n",
    "             tuner = kt.BayesianOptimization(\n",
    "                 hypermodel=build_lstm_model,\n",
    "                 objective=kt.Objective(\"val_loss\", direction=\"min\"), # Explicitly define objective\n",
    "                 max_trials=KERAS_TUNER_MAX_TRIALS,\n",
    "                 executions_per_trial=KERAS_TUNER_EXECUTIONS,\n",
    "                 directory='keras_tuner_dir', # Saves logs/checkpoints here\n",
    "                 project_name=KERAS_TUNER_PROJECT_NAME,\n",
    "                 overwrite=True\n",
    "             )\n",
    "\n",
    "             # Define EarlyStopping for the search phase\n",
    "             search_early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0)\n",
    "\n",
    "             # Run the search\n",
    "             print(f\"Running KerasTuner search for {KERAS_TUNER_MAX_TRIALS} trials...\")\n",
    "             tuner.search(X_train, y_train,\n",
    "                          epochs=SEARCH_EPOCHS, # Max epochs PER TRIAL\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          validation_data=(X_val, y_val),\n",
    "                          callbacks=[search_early_stopping],\n",
    "                          verbose=0 # Set to 1 for detailed trial logs\n",
    "                         )\n",
    "\n",
    "             print(\"\\nHyperparameter search finished.\")\n",
    "             # Show summary of top trial(s)\n",
    "             tuner.results_summary(num_trials=1)\n",
    "\n",
    "             # Get the optimal hyperparameters\n",
    "             try:\n",
    "                best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "                print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal hyperparameters found are:\n",
    "- Units: {best_hps.get('units')}\n",
    "- Dropout: {best_hps.get('dropout'):.2f}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "                \"\"\")\n",
    "\n",
    "                # --- 6. Build and Train FINAL Model with Best Hyperparameters ---\n",
    "                print(\"\\nBuilding and training final model with best hyperparameters...\")\n",
    "                final_model = tuner.hypermodel.build(best_hps) # Build model with best HPs\n",
    "\n",
    "                # Define EarlyStopping for the final training phase\n",
    "                final_early_stopping = EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                                      restore_best_weights=True, verbose=1)\n",
    "\n",
    "                # Train the final model\n",
    "                history = final_model.fit(\n",
    "                    X_train, y_train,\n",
    "                    epochs=FINAL_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[final_early_stopping],\n",
    "                    verbose=1\n",
    "                )\n",
    "                print(\"Final model training finished.\")\n",
    "\n",
    "             except Exception as e:\n",
    "                print(f\"Error retrieving best HPs or building/training final model: {e}\")\n",
    "                final_model = None # Ensure model is None if this fails\n",
    "\n",
    "\n",
    "    # --- 7. Evaluate FINAL Model on Validation Set ---\n",
    "    # Check scaler and final_model exist, and validation data exists\n",
    "    if final_model is not None and scaler is not None and 'X_val' in locals() and X_val.shape[0] > 0:\n",
    "        print(f\"\\n--- Evaluating FINAL Tuned LSTM Model on {VALIDATION_YEAR} Validation Data ---\")\n",
    "        print(\"Predicting...\")\n",
    "        # Ensure X_val has data before predicting\n",
    "        if X_val.shape[0] > 0:\n",
    "            predictions_scaled = final_model.predict(X_val)\n",
    "            print(\"Inverse transforming...\")\n",
    "            try:\n",
    "                 predictions_inv = scaler.inverse_transform(predictions_scaled)\n",
    "                 actuals_inv = y_val_actual_unscaled\n",
    "\n",
    "                 min_len_eval = min(len(actuals_inv), len(predictions_inv))\n",
    "                 if len(actuals_inv) != len(predictions_inv): print(f\"Warn: Length mismatch final eval. Truncating to {min_len_eval}.\")\n",
    "                 actuals_inv = actuals_inv[:min_len_eval]\n",
    "                 predictions_inv = predictions_inv[:min_len_eval]\n",
    "                 dates_val_plot = dates_val_for_plotting[:min_len_eval]\n",
    "\n",
    "                 # Calculate metrics\n",
    "                 if len(actuals_inv) > 0:\n",
    "                     r2_val, mae_val, mse_val = calculate_metrics(actuals_inv, predictions_inv)\n",
    "                     print(f\"FINAL Tuned Validation R-squared (R2): {r2_val:.4f}\")\n",
    "                     print(f\"FINAL Tuned Validation Mean Absolute Error (MAE): {mae_val:.2f}\")\n",
    "                     print(f\"FINAL Tuned Validation Mean Squared Error (MSE): {mse_val:.2f}\")\n",
    "\n",
    "                     # --- 8. Plot Validation Results ---\n",
    "                     print(f\"\\n--- Plotting FINAL Validation Results for {PRIMARY_TARGET} (Actual vs. Predicted {VALIDATION_YEAR}) ---\")\n",
    "                     plot_title_val = f'TUNED LSTM Validation (Nashik/Wheat): {PRIMARY_TARGET.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()} Price (Actual vs. Predicted {VALIDATION_YEAR})'\n",
    "                     fig_val = plot_lstm_validation_results(dates_val_plot, actuals_inv, predictions_inv, PRIMARY_TARGET, plot_title_val)\n",
    "                     fig_val.show()\n",
    "                 else: print(\"Skipping metrics/plotting: No valid aligned data after inverse transform.\")\n",
    "            except Exception as e: print(f\"Error during final prediction/scaling/eval: {e}\"); traceback.print_exc()\n",
    "        else:\n",
    "            print(\"Skipping prediction and evaluation as X_val is empty.\")\n",
    "\n",
    "    elif final_model is None: print(\"\\nSkipping final evaluation (Model not trained or failed).\")\n",
    "    else: print(\"\\nCannot proceed: lack of data after filtering/sequencing or scaler missing.\")\n",
    "else: print(\"\\nFailed: check data loading, preprocessing, or mapping lookup.\")\n",
    "\n",
    "print(\"\\nProcess finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a285c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
