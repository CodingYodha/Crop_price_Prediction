{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a61c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Crop Price Time Series Forecasting ---\n",
      "Forecasting from current date: 2025-04-06\n",
      "Successfully loaded data from E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_21_24.csv\n",
      "Data preprocessing complete. 27676 rows remaining.\n",
      "\n",
      "Filtering data for State='Maharashtra', District='Akola', Commodity='Wheat'...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 175\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df_full \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# --- Filtering Data Based on User Selections ---\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFiltering data for State=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSELECTED_STATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, District=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSELECTED_DISTRICT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, Commodity=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSELECTED_COMMODITY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    174\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m df_full[\n\u001b[1;32m--> 175\u001b[0m         (\u001b[43mdf_full\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m SELECTED_STATE\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m    176\u001b[0m         (df_full[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistrict_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m SELECTED_DISTRICT\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m    177\u001b[0m         (df_full[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommodity_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m SELECTED_COMMODITY\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m    178\u001b[0m     ]\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# Use copy to avoid SettingWithCopyWarning\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# Ensure data is sorted by date (important for plotting historical correctly)\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     filtered_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39mDATE_COLUMN, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from IPython.display import display # Optional: for better dataframe rendering in notebooks\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_PATH = r\"E:\\elevatetrsest\\crop price predictor\\Crop_price_Prediction\\data\\edited_21_24.csv\"  # Make sure this file is in the same directory or provide the full path\n",
    "TARGET_COLUMNS = ['avg_min_price', 'avg_max_price', 'avg_modal_price']\n",
    "DATE_COLUMN = 'date'\n",
    "MIN_DATA_POINTS = 30 # Minimum data points required to train a model\n",
    "\n",
    "# --- User Selections (Replace Streamlit Sidebar Inputs) ---\n",
    "# Set these values manually for your desired forecast\n",
    "SELECTED_STATE = \"Maharashtra\"  # Example: Choose a state from your data\n",
    "SELECTED_DISTRICT = \"Akola\"     # Example: Choose a district\n",
    "SELECTED_COMMODITY = \"Wheat\"    # Example: Choose a commodity\n",
    "FORECAST_DAYS = 90             # Example: Forecast period\n",
    "\n",
    "# --- Data Loading Function ---\n",
    "def load_data(path):\n",
    "    \"\"\"Loads and preprocesses the data.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"Successfully loaded data from {path}\")\n",
    "\n",
    "        # Basic Preprocessing\n",
    "        df[DATE_COLUMN] = pd.to_datetime(df[DATE_COLUMN], errors='coerce')\n",
    "        initial_rows = len(df)\n",
    "        df.dropna(subset=[DATE_COLUMN], inplace=True) # Drop rows where date conversion failed\n",
    "        if initial_rows > len(df):\n",
    "             print(f\"Dropped {initial_rows - len(df)} rows due to invalid dates.\")\n",
    "\n",
    "        # Ensure price columns are numeric, coerce errors to NaN\n",
    "        for col in TARGET_COLUMNS:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "        # Optional: Impute missing prices if needed (example using ffill per group)\n",
    "        # print(\"Attempting forward fill for missing prices within groups...\")\n",
    "        # df.sort_values([DATE_COLUMN,'state_name', 'district_name', 'commodity_name'], inplace=True)\n",
    "        # df[TARGET_COLUMNS] = df.groupby(['state_name', 'district_name', 'commodity_name'])[TARGET_COLUMNS].ffill()\n",
    "\n",
    "        initial_rows = len(df)\n",
    "        df.dropna(subset=TARGET_COLUMNS, inplace=True) # Drop rows with missing target values\n",
    "        if initial_rows > len(df):\n",
    "             print(f\"Dropped {initial_rows - len(df)} rows due to missing price data after preprocessing.\")\n",
    "\n",
    "        df.sort_values(DATE_COLUMN, inplace=True)\n",
    "        print(f\"Data preprocessing complete. {len(df)} rows remaining.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file not found at {path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or preprocessing data: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Modeling Function ---\n",
    "def train_and_forecast(data, target_column, forecast_periods):\n",
    "    \"\"\"Trains a Prophet model and returns the model, forecast (starting from today),\n",
    "       and predictions on the historical data for evaluation.\"\"\"\n",
    "    # Prepare data for Prophet (requires 'ds' and 'y' columns)\n",
    "    prophet_df = data[[DATE_COLUMN, target_column]].rename(columns={DATE_COLUMN: 'ds', target_column: 'y'})\n",
    "\n",
    "    # Check for sufficient data points for training\n",
    "    if len(prophet_df) < MIN_DATA_POINTS:\n",
    "        print(f\"Warning: Not enough historical data points ({len(prophet_df)}) for '{target_column}' in the selected group to train. Need at least {MIN_DATA_POINTS}. Skipping forecast.\")\n",
    "        return None, None, None # Return None for model, forecast, and historical predictions\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nTraining Prophet model for '{target_column}'...\")\n",
    "        # Instantiate and fit Prophet model on historical data\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=False, # Adjust based on expected patterns\n",
    "            daily_seasonality=False   # Adjust based on expected patterns\n",
    "        )\n",
    "        model.fit(prophet_df) # Fit the model using historical data\n",
    "        print(\"Model training complete.\")\n",
    "\n",
    "        # --- Create future dataframe STARTING FROM TODAY ---\n",
    "        # Get today's date (midnight) based on system time when script runs\n",
    "        current_date = pd.Timestamp.now().normalize()\n",
    "        # Create a sequence of dates starting from today for the forecast period\n",
    "        future_dates = pd.date_range(start=current_date, periods=forecast_periods, freq='D')\n",
    "        future_df = pd.DataFrame({'ds': future_dates})\n",
    "        # ----------------------------------------------------\n",
    "\n",
    "        # Generate forecast using the dates starting from today\n",
    "        print(f\"Generating {forecast_periods}-day forecast starting from {current_date.strftime('%Y-%m-%d')}...\")\n",
    "        forecast = model.predict(future_df)\n",
    "        print(\"Forecast generation complete.\")\n",
    "\n",
    "        # Generate predictions on historical data for evaluation\n",
    "        historical_preds = model.predict(prophet_df) # Predict on the same data used for training\n",
    "\n",
    "        return model, forecast, historical_preds # Return model, future forecast, historical predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Prophet modeling or forecasting for {target_column}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# --- Plotting Function for a Single Target ---\n",
    "def plot_single_forecast(historical_data, forecast_data, target_column, title):\n",
    "    \"\"\"Creates a Plotly figure for one target's historical data and forecast.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    target_label = target_column.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize() # Clean label for display\n",
    "\n",
    "    # Add historical data trace\n",
    "    hist_data_col = historical_data[[DATE_COLUMN, target_column]].dropna()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=hist_data_col[DATE_COLUMN],\n",
    "        y=hist_data_col[target_column],\n",
    "        mode='lines',\n",
    "        name=f'Historical {target_label}',\n",
    "        line=dict(color='blue')\n",
    "    ))\n",
    "\n",
    "    # Add forecast trace (starts from today)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=forecast_data['ds'],\n",
    "        y=forecast_data['yhat'],\n",
    "        mode='lines',\n",
    "        name=f'Forecast {target_label}',\n",
    "        line=dict(color='red', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # Add uncertainty interval for the forecast\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=forecast_data['ds'],\n",
    "        y=forecast_data['yhat_upper'],\n",
    "        mode='lines', name='Forecast Upper Bound',\n",
    "        line=dict(width=0),\n",
    "        showlegend=False\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=forecast_data['ds'],\n",
    "        y=forecast_data['yhat_lower'],\n",
    "        mode='lines', name='Forecast Lower Bound',\n",
    "        line=dict(width=0),\n",
    "        fillcolor='rgba(255, 0, 0, 0.2)', # Light red fill for uncertainty\n",
    "        fill='tonexty',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title=f'Price ({target_label})',\n",
    "        hovermode=\"x unified\",\n",
    "        legend_title_text='Legend'\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Evaluation Metrics Function ---\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculates and returns R2, MAE, and MSE.\"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return r2, mae, mse\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "print(\"--- Crop Price Time Series Forecasting ---\")\n",
    "print(f\"Forecasting from current date: {pd.Timestamp.now().normalize().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Load data\n",
    "df_full = load_data(DATA_PATH)\n",
    "\n",
    "if df_full is not None:\n",
    "    # --- Filtering Data Based on User Selections ---\n",
    "    print(f\"\\nFiltering data for State='{SELECTED_STATE}', District='{SELECTED_DISTRICT}', Commodity='{SELECTED_COMMODITY}'...\")\n",
    "    filtered_df = df_full[\n",
    "        (df_full['state_name'].str.strip().str.lower() == SELECTED_STATE.strip().lower()) &\n",
    "        (df_full['district_name'].str.strip().str.lower() == SELECTED_DISTRICT.strip().lower()) &\n",
    "        (df_full['commodity_name'].str.strip().str.lower() == SELECTED_COMMODITY.strip().lower())\n",
    "    ].copy() # Use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Ensure data is sorted by date (important for plotting historical correctly)\n",
    "    filtered_df.sort_values(by=DATE_COLUMN, inplace=True)\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"\\nWarning: No historical data found for the selected combination.\")\n",
    "        print(\"Please check the CSV file and your selections (State, District, Commodity).\")\n",
    "    else:\n",
    "        last_hist_date = filtered_df[DATE_COLUMN].max().strftime('%Y-%m-%d')\n",
    "        print(f\"\\nFound {len(filtered_df)} historical data points (Latest: {last_hist_date}).\")\n",
    "        print(f\"Proceeding with forecast for {FORECAST_DAYS} days.\")\n",
    "\n",
    "        all_forecasts = {} # Dictionary to store forecasts if needed later\n",
    "\n",
    "        # Loop through each target price type\n",
    "        for target in TARGET_COLUMNS:\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"Processing Target: {target}\")\n",
    "\n",
    "            # Check if target column exists and has data after filtering\n",
    "            if target not in filtered_df.columns or filtered_df[target].isnull().all():\n",
    "                print(f\"Warning: Target column '{target}' not found or contains only null values for the selection. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Prepare data for this specific target (dropping NaNs for this target)\n",
    "            target_df = filtered_df[[DATE_COLUMN, target]].dropna().copy()\n",
    "            if target_df.empty:\n",
    "                 print(f\"Warning: No valid data points for '{target}' after dropping NaNs. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            # Train model, get forecast (future dates), and get historical predictions\n",
    "            model, forecast, historical_preds = train_and_forecast(target_df, target, FORECAST_DAYS)\n",
    "\n",
    "            if forecast is not None and historical_preds is not None:\n",
    "                all_forecasts[target] = forecast # Store the forecast\n",
    "\n",
    "                # --- Evaluate Model Fit on Historical Data ---\n",
    "                print(f\"\\n--- Evaluating Model Fit for {target} (on historical data) ---\")\n",
    "                actuals = target_df[target] # Ground truth from the training data\n",
    "                preds = historical_preds['yhat'] # Predictions on the training data\n",
    "                \n",
    "                # Ensure alignment - Prophet predictions match the input df length/order\n",
    "                if len(actuals) == len(preds):\n",
    "                    r2, mae, mse = calculate_metrics(actuals, preds)\n",
    "                    print(f\"R-squared (R2): {r2:.4f}\")\n",
    "                    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "                    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "                else:\n",
    "                    print(\"Warning: Mismatch between actuals and predictions length. Cannot calculate metrics accurately.\")\n",
    "                    print(f\"Actuals length: {len(actuals)}, Predictions length: {len(preds)}\")\n",
    "\n",
    "\n",
    "                # --- Plot Historical Data and Forecast ---\n",
    "                print(f\"\\n--- Plotting Historical Data & Forecast for {target} ---\")\n",
    "                plot_title = f'{target.replace(\"avg_\", \"\").replace(\"_price\", \"\").capitalize()} Price: Historical & {FORECAST_DAYS}-Day Forecast\\n({SELECTED_COMMODITY} in {SELECTED_DISTRICT}, {SELECTED_STATE})'\n",
    "                fig = plot_single_forecast(target_df, forecast, target, plot_title)\n",
    "                fig.show() # Display the plot in the notebook output\n",
    "\n",
    "                # --- Display Forecast Data Table ---\n",
    "                print(f\"\\n--- Forecast Data Table for {target} ({FORECAST_DAYS} days) ---\")\n",
    "                f_display = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].copy()\n",
    "                f_display.columns = ['Date', 'Forecast', 'Lower Bound', 'Upper Bound']\n",
    "                f_display['Date'] = f_display['Date'].dt.strftime('%Y-%m-%d') # Format date\n",
    "                # Use display for potentially nicer formatting in Jupyter, or just print\n",
    "                display(f_display.set_index('Date').style.format(\"{:.2f}\"))\n",
    "                # Alternatively: print(f_display.set_index('Date').round(2).to_string())\n",
    "\n",
    "            else:\n",
    "                # Message already printed in train_and_forecast if skipped\n",
    "                print(f\"Skipping results display for {target} due to insufficient data or error during modeling.\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "        print(\"\\nForecasting process finished.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nFailed to load data. Cannot run the forecasting process.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
